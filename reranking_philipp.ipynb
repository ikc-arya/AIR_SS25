{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing query and collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask_4b/subtask4b_collection_data.pkl' \n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "PATH_QUERY_TRAIN_DATA = 'subtask_4b/subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask_4b/subtask4b_query_tweets_dev.tsv' \n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "szMEK3OkYLvX"
   },
   "outputs": [],
   "source": [
    "#df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2) Running the BM25 baseline\n",
    "The following code runs a BM25 baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:100] # @k: how many docs shall the ranked list include?\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top50 candidates using the BM25 model\n",
    "\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "if not os.path.exists(train_pkl_path):\n",
    "    df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_train.to_pickle(train_pkl_path)\n",
    "else:\n",
    "    df_query_train = pd.read_pickle(train_pkl_path)\n",
    "\n",
    "if not os.path.exists(dev_pkl_path):\n",
    "    df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_dev.to_pickle(dev_pkl_path)\n",
    "else:\n",
    "    df_query_dev = pd.read_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Neural Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BM25 pre-ranked query dataframes\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) ColBERT w/ fine-tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings of a specified text passage from some model\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "# pre compute all the token embeddings of the documents\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    max_len=512,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    print(\"Precomputing document embeddings.\")\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        output = model(**inputs)\n",
    "        token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "        token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cuda(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving document {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# either precompute or load precomputed doc embeddings\n",
    "def get_precomputed_doc_embeddings(save_name):\n",
    "    def split_at_slash(s):\n",
    "        if '/' in s:\n",
    "            return s.split('/', 1)\n",
    "        else:\n",
    "            return ['', s]\n",
    "        \n",
    "    if not os.path.exists(\"doc_embeddings_\" + split_at_slash(save_name)[1] + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, model_name=save_name, save_dir=save_name, device=\"cuda\")\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training dataset by getting the positive and a random negative document for each query\n",
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, tokenizer, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# basic ColBERT scoring i.e. match matrix aggregation\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "    return max_sim_per_q.sum()\n",
    "\n",
    "# finetuning some BERT-model to get higher ColBERT-score \n",
    "# for the positive document than for the negative (per query)\n",
    "def bert_finetune(save_name, MARGIN=0.5, BATCH_SIZE=8, EPOCHS=6, LR=2e-5, num_negatives=1):    \n",
    "    model_name = \"allenai/scibert_scivocab_uncased\" # specify baseline BERT model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    metadata = get_precomputed_doc_embeddings(model_name)\n",
    "\n",
    "    # create training triplets\n",
    "    train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer, num_negatives)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # optimizer\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "    \n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            q_emb_batch = outputs.last_hidden_state  # [B, L, D]\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [emb[mask] for emb, mask in zip(q_emb_batch, attention_mask)]\n",
    "    \n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "    \n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(DEVICE)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(DEVICE)[:metadata[neg_ids[i]][\"length\"]]\n",
    "    \n",
    "                q_emb = q_embs[i]\n",
    "                score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "                score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "    \n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "    \n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "    \n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    model.save_pretrained(save_name)\n",
    "    tokenizer.save_pretrained(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e0d8fd128c441ba6879ad92adbd2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c52b53071442448a2f2510d6bbb3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 188.6070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3398b0acd94d729bc39273e73a97f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 81.0262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebd98f5404d464f8c6bfda1553e69cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 35.0394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c080300d8d1f43539e6983da228d9c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 18.8931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a2da514cd746eba7ac57eef0e5eeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 16.2508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fc87a166be4e6b973f62b169829666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 12.9944\n"
     ]
    }
   ],
   "source": [
    "bert_finetune(\"colB_sciB_marg05\", MARGIN=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, model, save_name):\n",
    "    device = next(model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model).to(device)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36c7d71d41ee404682f2b873329a0770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# specify model for re-ranking\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# pre-compute embeddings\n",
    "metadata = get_precomputed_doc_embeddings(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b28fc68655b54bd5977e4e76d4810c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 4) Evaluation\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BM25 Baseline ----\n",
      "Results on the train set: {1: 0.5731735781529604, 5: 0.625250914183459, 10: 0.6308237901348459}\n",
      "Results on the dev set: {1: 0.5657142857142857, 5: 0.616095238095238, 10: 0.6224325396825396}\n"
     ]
    }
   ],
   "source": [
    "# ---- BM25 Baseline ----\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "\n",
    "print(\"---- BM25 Baseline ----\")\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune-4: ColBERT (SciBERT) ----\n",
      "MRR@5: 0.6806309523809524\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking @ Margin 0.5 ----\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.6532380952380952\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking @ Margin 0.6 ----\n",
    "model_name = \"colB_sciBERT_marg06\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results documentation\n",
    "\n",
    "### 1) SciBERT in ColBERT architecture\n",
    "Re-Ranking of top 50 BM25 results for each query:\n",
    "- SciBERT (ColBERT)\n",
    "    - used SciBERT model out of the box\n",
    "- SciBERT (ColBERT) @ 2EP\n",
    "    - fine tuned SciBERT in 2 epochs on train data\n",
    "- SciBERT (ColBERT) @ 4EP\n",
    "    - based on previous fine tune (SciBERT (ColBERT) @ 2EP), fine tuned SciBERT in additional 2 epochs, resulting in 4 epochs fine tune compared to out of the box SciBERT\n",
    "- SciBERT (ColBERT) @ 8EP\n",
    "    - based on previous fine tune (SciBERT (ColBERT) @ 4EP), fine tuned SciBERT in additional 4 epochs, resulting in 8 epochs fine tune compared to out of the box SciBERT\n",
    "\n",
    "Hyperparameters:\n",
    "- BATCH_SIZE = 8\n",
    "- LR = 2e-5\n",
    "- MARGIN = 0.2\n",
    "\n",
    "Loss Function: <br>\n",
    "loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "|Model                        | MRR@5 (dev)     |\n",
    "|-----------------------------|-----------------|\n",
    "|BM25 (baseline)              |55.20%           |\n",
    "|SciBERT (ColBERT)            |56.94%           | \n",
    "|SciBERT (ColBERT) @ 2EP      |63.51%           |\n",
    "|SciBERT (ColBERT) @ 4EP      |64.02%           |\n",
    "|SciBERT (ColBERT) @ 8EP      |62.26%           |\n",
    "\n",
    "#### 1.1) Grid search for finding best margin and number of negative samples\n",
    "| Margin | Negatives | MRR@5     | Last Epoch Loss |\n",
    "|--------|-----------|-----------|--------------|\n",
    "| 0.3    | 1         | 0.6537    | 8.0212       |\n",
    "| 0.3    | 2         | 0.6477    | 16.7373      |\n",
    "| 0.3    | 4         | 0.6118    | 29.3307      |\n",
    "| 0.4    | 1         | 0.6574    | 12.9181      |\n",
    "| 0.4    | 2         | 0.6503    | 21.4273      |\n",
    "| 0.4    | 4         | 0.6360    | 27.8490      |\n",
    "| **0.5**    | **1**         | **0.6610**    | **9.6190**       |\n",
    "| 0.5    | 2         | 0.6393    | 18.1380      |\n",
    "| 0.5    | 4         | 0.6259    | 31.5070      |\n",
    "\n",
    "For margin 0.6 MRR@5 goes down again: 0.6532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 5) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "model_name = \"bm25\"\n",
    "\n",
    "df_query_dev['preds'] = df_query_dev[f'{model_name}_topk'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## _) Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out different combinations of margin and number of negative document samples for training. <br>\n",
    "Result: **margin of 0.5** seems to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Combination 1/9 ‚Üí colB_sciB_m3_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e09fd20c50d409ebe8b5d34d2509a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 121.9535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce646d659fb4e41b08da114668cbaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 40.3961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7006d7f1386a415097e935b7caabf68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 23.0165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd8b1e60ce547c28be5201422780adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 12.7019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9d31848ba8425192565230a9a06a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 7.5942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6b108b62d7450c95fea059f8215ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 8.0212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434f634c3cd24aec8b6bcbd9cc159524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa40856f46154657ac80b44ffc783e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6537142857142857\n",
      "\n",
      "üîç Combination 2/9 ‚Üí colB_sciB_m3_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b25f30c0936409fb0fbb0dcdd7401fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 198.2437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91809150dd6e432489c4d4ae3f51766f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 72.1588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427c256ec2d64d46b75eaa459975ba7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 46.9973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40265b6e4e114bb28f3e837fbad949dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 28.1074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98ebe27ef4c4702a8c3c9d0be795069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 23.5954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccacc3304416419aae3e09b1ca095ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 16.7373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a73804eaf94e679dab3916598549d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b5ad6ecad14b73b81c3696a13a008e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6477142857142858\n",
      "\n",
      "üîç Combination 3/9 ‚Üí colB_sciB_m3_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6604e85353f4c1a96259cadd04081e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 352.6436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bf50ff4c047499d2dfb370889d950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 134.0740\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e271355e337447288da685f9b87b7973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 63.8498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78562c0afd264b4584e06c645241410c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 42.9125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09550471fdbe4919b96ff06abdd36478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 31.2010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9277c4e6eb546dd863ff12062d79515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 29.3307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4115a60c084d6395f46b080e7fd6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2360f807306d40b89a8fc0ba1090fb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6118333333333333\n",
      "\n",
      "üîç Combination 4/9 ‚Üí colB_sciB_m4_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593927cd5bca4ca3ac111a150d9b53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 137.3641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57159f0497db4ae4ad6d36681103cac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 52.0689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e20806081b4f37b21276934af8b242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 23.6070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944a5737a791440a914e9b5d11d54e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 17.4979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b31d92c4e34faf9b43a4dd3611b5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 9.9772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeafdd544164f73858f00e68a63d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 12.9181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98e12e3bcf8477fae34ef1e10415b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb2ada83d4e45faadb6c6d5624716c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6574285714285714\n",
      "\n",
      "üîç Combination 5/9 ‚Üí colB_sciB_m4_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ddde22bf034ba98eaeccb4fe279cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 227.4885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e6a8f8fbbd43598593fa5926d2b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 92.5719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617c1746f60642bd971136494b77f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 51.2666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef09260d944427b93542f1894133e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 30.8887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac6e855bac04f9ebb710b8d465f8f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 23.0024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b193e5ef064a5eafa9104ed9f9905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 21.4273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce41852813a4b42963c1e89c6ec7768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47536aeb7564a889d467e9bee1ef001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6502738095238095\n",
      "\n",
      "üîç Combination 6/9 ‚Üí colB_sciB_m4_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc0f00d8674524a4c54db1c280d060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 359.6384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c4f4165e174428abdd3251ec323e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 131.8794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bce1c803e545c5a5a1c4bfce51dc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 63.0106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db41e5652b449cd8feb4ed1cf6b9ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 50.9670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653aca41aac94923a2b5abff30e99165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 38.3159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc814c63b0741179b9ffafc0160d6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 27.8490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b82887947f449b88699c1135c500131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e8595fee134e92a18585517abb9b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6360357142857143\n",
      "\n",
      "üîç Combination 7/9 ‚Üí colB_sciB_m5_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e8abe7a3b475d824558eb9512204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 160.1443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7de1ecf5214502a22416d6282d2b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 65.4520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e46e209ea454d08b9cc42b2ecf33f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 29.0368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa0fc891e9434a94f198165c36d72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 29.2456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e2d964e5d458aa9b0c251ca8cef50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 15.5198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da3178ba6a8410b9e637e6fa5752e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 9.6190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8d828954cc4db39e478692e6ccd77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9106981208d4bbd9057d9294488308c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6610238095238096\n",
      "\n",
      "üîç Combination 8/9 ‚Üí colB_sciB_m5_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66b958180604afbbae332786422c136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 257.0342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58015fc0f4274bb59808c8af376bf9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 89.1174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba91ac191984cd4bfb8bc659b1c3556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 41.8070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fc8466afb24a0c9c22d200ea70d180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 29.2456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2a5703f7ef4c45acc8809d3904d341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 21.2743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1c5421d9bd42fcafc5d75ec2080b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 18.1380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbfaaf3b73b43de902d88bcf4c6b107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d493c1b3b046b8b3878cbd77466f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.639345238095238\n",
      "\n",
      "üîç Combination 9/9 ‚Üí colB_sciB_m5_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81e1017b6c64e53901d6bc61540cd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 395.6334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc07155334146f387fa3a27d7e95942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 110.6216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c71da866c4fadbec85a2ede4b2b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 54.9982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eca26adc2b49649f7c278260ccf9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 41.8254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df868072a7840d8b75f19ff664b015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 32.5702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ef41191df1453dbb31ecbedb0c7a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 31.5070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a44c1bb14884babb2160e056665fbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2638ace67ba542a3b901180dcb591135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6259285714285714\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import random, torch, numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"margin\":        [0.3, 0.4, 0.5],\n",
    "    \"num_negatives\": [1, 2, 4]\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "for i, (margin, num_neg) in enumerate(product(*values), 1):\n",
    "    set_seed()\n",
    "    model_name = f\"colB_sciB_m{str(margin)[-1]}_neg{num_neg}\"\n",
    "    print(f\"\\nüîç Combination {i}/9 ‚Üí {model_name}\")\n",
    "\n",
    "    scibert_finetune(\n",
    "        save_name      = model_name,\n",
    "        MARGIN         = margin,\n",
    "        BATCH_SIZE     = 8,\n",
    "        EPOCHS         = 6,\n",
    "        LR             = 2e-5,\n",
    "        num_negatives  = num_neg\n",
    "    )\n",
    "\n",
    "    # ---------- Evaluation ----------\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model     = AutoModel.from_pretrained(model_name)\n",
    "    metadata  = pre_compute_embeddings(model_name)\n",
    "\n",
    "    df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, model_name)\n",
    "    mrr_scores   = get_performance_mrr(df_query_dev, \"cord_uid\", f\"{model_name}_topk\")\n",
    "    print(\"MRR@5:\", mrr_scores[5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Baseline: ColBERT architecture with SciBERT\n",
    "Use a pretrained SciBERT model to:\n",
    "- embed each query-token\n",
    "- embed each doc-token (can be pre-computed)\n",
    "\n",
    "For each query-doc pair:\n",
    "- calculate match-matrix: each query-token ‚Äì¬†doc-token pair gets cosine similarity value\n",
    "- aggregate the score: \n",
    "    - for each query-token take max cosine similarity value with corresponding doc-tokens\n",
    "    - sum over all of the max elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    max_len=512,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        output = model(**inputs)\n",
    "        token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "        token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cuda(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Speichern von {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_compute_embeddings(save_name):\n",
    "    if not os.path.exists(\"doc_embeddings_\" + save_name + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, model_name=model_name, save_dir=save_name, device=\"cuda\")\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, model, save_name):\n",
    "    device = next(model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model).to(device)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# settings for model run:\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "save_name = \"scibert_baseline\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-compute embeddings\n",
    "metadata = pre_compute_embeddings(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-rank BM25 list for train data\n",
    "df_query_train = rerank(df_query_train, metadata, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERT w/ fine-tuned SciBERT for docs and CTBERT for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "\n",
    "# hyperparameter\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 4\n",
    "LR = 2e-5\n",
    "MARGIN = 0.2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load model\n",
    "query_model_name = \"digitalepidemiologylab/covid-twitter-bert\"\n",
    "doc_model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "query_tokenizer = AutoTokenizer.from_pretrained(query_model_name)\n",
    "doc_tokenizer = AutoTokenizer.from_pretrained(doc_model_name)\n",
    "\n",
    "query_model = AutoModel.from_pretrained(query_model_name).to(DEVICE)\n",
    "doc_model = AutoModel.from_pretrained(doc_model_name).to(DEVICE)\n",
    "\n",
    "# projection to same dimensions\n",
    "query_projection = nn.Linear(1024, 768).to(DEVICE)\n",
    "\n",
    "# dataset creation\n",
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# helper functions\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    return token_embeddings[attention_mask]\n",
    "\n",
    "def get_doc_embedding(doc_id, metadata, tokenizer, model, device):\n",
    "    text = f\"{metadata[doc_id]['title']} {metadata[doc_id]['abstract']} Authors: {metadata[doc_id]['authors']}\"\n",
    "    return get_token_embeddings(text, tokenizer, model, device)\n",
    "\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    return sim_matrix.max(dim=1).values.sum()\n",
    "\n",
    "# training function\n",
    "def train_colbert_dual_encoder(df_query_train, metadata):\n",
    "    dataset = ColBERTTripletDataset(df_query_train, metadata)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    query_model.train()\n",
    "    doc_model.train()\n",
    "    query_projection.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        list(query_model.parameters()) +\n",
    "        list(doc_model.parameters()) +\n",
    "        list(query_projection.parameters()),\n",
    "        lr=LR\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "\n",
    "            inputs = query_tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = query_model(**inputs)\n",
    "            q_emb_batch = outputs.last_hidden_state\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [query_projection(emb[mask]) for emb, mask in zip(q_emb_batch, attention_mask)]\n",
    "\n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "\n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = get_doc_embedding(pos_ids[i], metadata, doc_tokenizer, doc_model, DEVICE)\n",
    "                d_neg_emb = get_doc_embedding(neg_ids[i], metadata, doc_tokenizer, doc_model, DEVICE)\n",
    "                q_emb = q_embs[i]\n",
    "\n",
    "                score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "                score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "\n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "\n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "\n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    query_model.save_pretrained(\"finetuned_ctbert\")\n",
    "    query_tokenizer.save_pretrained(\"finetuned_ctbert\")\n",
    "    doc_model.save_pretrained(\"finetuned_scibert\")\n",
    "    doc_tokenizer.save_pretrained(\"finetuned_scibert\")\n",
    "    torch.save(query_projection.state_dict(), \"query_projection.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_colbert_dual_encoder(df_query_train, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, q_model, d_model, save_name):\n",
    "    device_q = next(q_model.parameters()).device\n",
    "    device_d = next(d_model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    query_projection = nn.Linear(1024, 768)\n",
    "    query_projection.load_state_dict(torch.load(\"query_projection.pt\"))\n",
    "    query_projection.to(device_q)\n",
    "    query_projection.eval()\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, q_model, device=device_q)\n",
    "            q_emb = query_projection(q_emb)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device_d)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7718/7718 [03:40<00:00, 34.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# pre-compute embeddings\n",
    "metadata = pre_compute_embeddings(\"finetuned_scibert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1400/1400 [02:21<00:00,  9.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, query_model, doc_model, \"sciCtBERT-1\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
