{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing query and collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask_4b/subtask4b_collection_data.pkl' \n",
    "\n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "PATH_QUERY_TRAIN_DATA = 'subtask_4b/subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask_4b/subtask4b_query_tweets_dev.tsv' \n",
    "\n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "szMEK3OkYLvX"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5\n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul\n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8\n",
       "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1\n",
       "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP"
   },
   "source": [
    "# 2) Running the BM25 baseline\n",
    "The following code runs a BM25 baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:100] # @k: how many docs shall the ranked list include?\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top50 candidates using the BM25 model\n",
    "\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "if not os.path.exists(train_pkl_path):\n",
    "    df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_train.to_pickle(train_pkl_path)\n",
    "else:\n",
    "    df_query_train = pd.read_pickle(train_pkl_path)\n",
    "\n",
    "if not os.path.exists(dev_pkl_path):\n",
    "    df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_dev.to_pickle(dev_pkl_path)\n",
    "else:\n",
    "    df_query_dev = pd.read_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Neural Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/philippmoessner/opt/miniconda3/envs/bm25_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Baseline: ColBERT architecture with SciBERT\n",
    "Use a pretrained SciBERT model to:\n",
    "- embed each query-token\n",
    "- embed each doc-token (can be pre-computed)\n",
    "\n",
    "For each query-doc pair:\n",
    "- calculate match-matrix: each query-token – doc-token pair gets cosine similarity value\n",
    "- aggregate the score: \n",
    "    - for each query-token take max cosine similarity value with corresponding doc-tokens\n",
    "    - sum over all of the max elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)  # [seq_len, hidden_dim]\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings  # Shape: [num_tokens, hidden_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    max_len=512,\n",
    "    save_dir=\"doc_chunks/\",\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "            token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "            attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "            token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cpu(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Speichern von {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-compute document embeddings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(\"doc_chunks/metadata.json\"):\n",
    "    metadata = build_and_save_doc_embeddings(df_collection, model_name=model_name, device=\"cpu\")\n",
    "else:\n",
    "    with open(\"doc_chunks/metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Re-Rank BM25 pre-ranked list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, model):\n",
    "    df['scibert_baseline_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        tweet_text = row['tweet_text']\n",
    "        pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "        q_emb = get_token_embeddings(tweet_text, tokenizer, model)\n",
    "        q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "        scores = []\n",
    "        for doc in pre_ranked_docs:\n",
    "            emb = torch.load(metadata[doc][\"path\"])\n",
    "            length = metadata[doc][\"length\"]\n",
    "            d_emb = emb[:length]\n",
    "            d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "            max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "            score = max_sim_per_q.sum().item()\n",
    "            scores.append(score)\n",
    "\n",
    "        df.at[idx, 'scibert_baseline_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row['scibert_baseline_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df['scibert_baseline_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1400 [00:00<?, ?it/s]<ipython-input-15-a0c9f489743a>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  emb = torch.load(metadata[doc][\"path\"])\n",
      "100%|██████████| 1400/1400 [05:40<00:00,  4.11it/s]\n"
     ]
    }
   ],
   "source": [
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/12853 [00:00<?, ?it/s]<ipython-input-15-a0c9f489743a>:14: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  emb = torch.load(metadata[doc][\"path\"])\n",
      "100%|██████████| 12853/12853 [50:30<00:00,  4.24it/s] \n"
     ]
    }
   ],
   "source": [
    "df_query_train = rerank(df_query_train, metadata, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_path = 'df_query_train_reranked_scibert.pkl'\n",
    "dev_pkl_path = 'df_query_dev_reranked_scibert.pkl'\n",
    "\n",
    "df_query_train.to_pickle(train_pkl_path)\n",
    "df_query_dev.to_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) ColBERT w/ fine-tuned SciBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_path = 'df_query_train_reranked_scibert.pkl'\n",
    "dev_pkl_path = 'df_query_dev_reranked_scibert.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]<ipython-input-24-0c0063ebb8d5>:61: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(DEVICE)[:metadata[pos_ids[i]][\"length\"]]\n",
      "<ipython-input-24-0c0063ebb8d5>:62: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(DEVICE)[:metadata[neg_ids[i]][\"length\"]]\n",
      "Epoch 1: 100%|██████████| 1607/1607 [25:11<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 80.1016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1607/1607 [25:14<00:00,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 28.7130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, tokenizer, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "    return max_sim_per_q.sum()\n",
    "\n",
    "# hyperparameters\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 2\n",
    "LR = 2e-5\n",
    "MARGIN = 0.2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# create training triplets\n",
    "train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# optimizer\n",
    "model.train()\n",
    "model.to(DEVICE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    total_loss = 0.0\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        queries, pos_ids, neg_ids = batch\n",
    "\n",
    "        inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "        inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "        outputs = model(**inputs)\n",
    "        q_emb_batch = outputs.last_hidden_state  # [B, L, D]\n",
    "        attention_mask = inputs[\"attention_mask\"].bool()\n",
    "        q_embs = [emb[mask] for emb, mask in zip(q_emb_batch, attention_mask)]  # list of [num_tokens, D]\n",
    "\n",
    "        score_pos_list = []\n",
    "        score_neg_list = []\n",
    "\n",
    "        for i in range(len(queries)):\n",
    "            d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(DEVICE)[:metadata[pos_ids[i]][\"length\"]]\n",
    "            d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(DEVICE)[:metadata[neg_ids[i]][\"length\"]]\n",
    "\n",
    "            q_emb = q_embs[i]\n",
    "            score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "            score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "\n",
    "            score_pos_list.append(score_pos)\n",
    "            score_neg_list.append(score_neg)\n",
    "\n",
    "        score_pos_batch = torch.stack(score_pos_list)\n",
    "        score_neg_batch = torch.stack(score_neg_list)\n",
    "\n",
    "        loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('colbert_scibert_finetune-1/tokenizer_config.json',\n",
       " 'colbert_scibert_finetune-1/special_tokens_map.json',\n",
       " 'colbert_scibert_finetune-1/vocab.txt',\n",
       " 'colbert_scibert_finetune-1/added_tokens.json',\n",
       " 'colbert_scibert_finetune-1/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"colbert_scibert_finetune-1\")\n",
    "tokenizer.save_pretrained(\"colbert_scibert_finetune-1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7718/7718 [21:19<00:00,  6.03it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"colbert_scibert_finetune-1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "embed_dir = \"doc_chunks-finetune-1/\"\n",
    "\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)  # [seq_len, hidden_dim]\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings  # Shape: [num_tokens, hidden_dim]\n",
    "\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    max_len=512,\n",
    "    save_dir=embed_dir,\n",
    "    device=\"cpu\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)\n",
    "            token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "            attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "            token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cpu(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Speichern von {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# pre-compute doc embeddings\n",
    "if not os.path.exists(embed_dir + \"metadata.json\"):\n",
    "    metadata = build_and_save_doc_embeddings(df_collection, model_name=model_name, device=\"cpu\")\n",
    "else:\n",
    "    with open(embed_dir + \"metadata.json\", \"r\") as f:\n",
    "        metadata = json.load(f)\n",
    "\n",
    "def rerank(df, metadata, tokenizer, model):\n",
    "    df['scibert_finetune-1_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "        tweet_text = row['tweet_text']\n",
    "        pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "        q_emb = get_token_embeddings(tweet_text, tokenizer, model)\n",
    "        q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "        scores = []\n",
    "        for doc in pre_ranked_docs:\n",
    "            emb = torch.load(metadata[doc][\"path\"])\n",
    "            length = metadata[doc][\"length\"]\n",
    "            d_emb = emb[:length]\n",
    "            d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "            max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "            score = max_sim_per_q.sum().item()\n",
    "            scores.append(score)\n",
    "\n",
    "        df.at[idx, 'scibert_finetune-1_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row['scibert_finetune-1_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df['scibert_finetune-1_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1400 [00:00<?, ?it/s]<ipython-input-26-bfdca2a03a40>:102: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  emb = torch.load(metadata[doc][\"path\"])\n",
      "100%|██████████| 1400/1400 [05:25<00:00,  4.31it/s]\n"
     ]
    }
   ],
   "source": [
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_train = rerank(df_query_train, metadata, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) ColBERT w/ fine-tuned SciBERT for docs and CTBERT for queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 4) Evaluation\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BM25 Baseline ----\n",
      "Results on the train set: {1: 0.5079747918773827, 5: 0.5508999196037242, 10: 0.5558827906275973}\n",
      "Results on the dev set: {1: 0.505, 5: 0.5520357142857142, 10: 0.5574200680272109}\n"
     ]
    }
   ],
   "source": [
    "# ---- BM25 Baseline ----\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "# Printed MRR@k results in the following format: {k: MRR@k}\n",
    "print(\"---- BM25 Baseline ----\")\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Baseline: ColBERT (SciBERT) ----\n",
      "Results on the train set: {1: 0.5081303975725512, 5: 0.5548354469773593, 10: 0.5600201422927634}\n",
      "Results on the dev set: {1: 0.53, 5: 0.569404761904762, 10: 0.5742800453514738}\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking Baseline ----\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'scibert_baseline_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'scibert_baseline_topk')\n",
    "# Printed MRR@k results in the following format: {k: MRR@k}\n",
    "print(\"---- Re-Ranking Baseline: ColBERT (SciBERT) ----\")\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune-1: ColBERT (SciBERT) ----\n",
      "Results on the dev set: {1: 0.5978571428571429, 5: 0.6351428571428571, 10: 0.6379787414965986}\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking Finetune-1 ----\n",
    "#results_train = get_performance_mrr(df_query_train, 'cord_uid', 'scibert_finetune-1_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'scibert_finetune-1_topk')\n",
    "# Printed MRR@k results in the following format: {k: MRR@k}\n",
    "print(\"---- Re-Ranking Finetune-1: ColBERT (SciBERT) ----\")\n",
    "#print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 5) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "df_query_dev['preds'] = df_query_dev['bm25_topk'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "bm25_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
