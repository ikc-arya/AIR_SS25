{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing query and collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask_4b/subtask4b_collection_data.pkl' \n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "PATH_QUERY_TRAIN_DATA = 'subtask_4b/subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask_4b/subtask4b_query_tweets_dev.tsv' \n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "szMEK3OkYLvX"
   },
   "outputs": [],
   "source": [
    "#df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 2) Running the BM25 baseline\n",
    "The following code runs a BM25 baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:100] # @k: how many docs shall the ranked list include?\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top50 candidates using the BM25 model\n",
    "\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "if not os.path.exists(train_pkl_path):\n",
    "    df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_train.to_pickle(train_pkl_path)\n",
    "else:\n",
    "    df_query_train = pd.read_pickle(train_pkl_path)\n",
    "\n",
    "if not os.path.exists(dev_pkl_path):\n",
    "    df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_dev.to_pickle(dev_pkl_path)\n",
    "else:\n",
    "    df_query_dev = pd.read_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Neural Re-Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BM25 pre-ranked query dataframes\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "test_pkl_path = 'df_query_test_top100.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)\n",
    "df_query_test = pd.read_pickle(test_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_path = 'df_query_train_top200.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top200.pkl'\n",
    "test_pkl_path = 'df_query_test_top200.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)\n",
    "df_query_test = pd.read_pickle(test_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_path = 'df_query_train_top50.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top50.pkl'\n",
    "test_pkl_path = 'df_query_test_top50.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)\n",
    "df_query_test = pd.read_pickle(test_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pkl_path = 'df_query_train_top25.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top25.pkl'\n",
    "test_pkl_path = 'df_query_test_top25.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)\n",
    "df_query_test = pd.read_pickle(test_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) ColBERT w/ fine-tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings of a specified text passage from some model\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "# pre compute all the token embeddings of the documents\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    max_len=512,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    print(\"Precomputing document embeddings.\")\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        output = model(**inputs)\n",
    "        token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "        token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cuda(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving document {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# either precompute or load precomputed doc embeddings\n",
    "def get_precomputed_doc_embeddings(save_name):\n",
    "    def split_at_slash(s):\n",
    "        if '/' in s:\n",
    "            return s.split('/', 1)\n",
    "        else:\n",
    "            return ['', s]\n",
    "        \n",
    "    if not os.path.exists(\"doc_embeddings_\" + split_at_slash(save_name)[1] + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, model_name=save_name, save_dir=save_name, device=\"cuda\")\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training dataset by getting the positive and a random negative document for each query\n",
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, tokenizer, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# basic ColBERT scoring i.e. match matrix aggregation\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "    return max_sim_per_q.sum()\n",
    "\n",
    "# finetuning some BERT-model to get higher ColBERT-score \n",
    "# for the positive document than for the negative (per query)\n",
    "def bert_finetune(save_name, MARGIN=0.5, BATCH_SIZE=8, EPOCHS=6, LR=2e-5, num_negatives=1):    \n",
    "    model_name = \"allenai/scibert_scivocab_uncased\" # specify baseline BERT model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    metadata = get_precomputed_doc_embeddings(model_name)\n",
    "\n",
    "    # create training triplets\n",
    "    train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer, num_negatives)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # optimizer\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "    \n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            q_emb_batch = outputs.last_hidden_state  # [B, L, D]\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [emb[mask] for emb, mask in zip(q_emb_batch, attention_mask)]\n",
    "    \n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "    \n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(DEVICE)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(DEVICE)[:metadata[neg_ids[i]][\"length\"]]\n",
    "    \n",
    "                q_emb = q_embs[i]\n",
    "                score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "                score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "    \n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "    \n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "    \n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    model.save_pretrained(save_name)\n",
    "    tokenizer.save_pretrained(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54e0d8fd128c441ba6879ad92adbd2a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9c52b53071442448a2f2510d6bbb3ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 188.6070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e3398b0acd94d729bc39273e73a97f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 81.0262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebd98f5404d464f8c6bfda1553e69cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 35.0394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c080300d8d1f43539e6983da228d9c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 18.8931\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2a2da514cd746eba7ac57eef0e5eeb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 16.2508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87fc87a166be4e6b973f62b169829666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 12.9944\n"
     ]
    }
   ],
   "source": [
    "bert_finetune(\"colB_sciB_marg05\", MARGIN=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, model, save_name):\n",
    "    device = next(model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model).to(device)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model for re-ranking\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# pre-compute embeddings\n",
    "metadata = get_precomputed_doc_embeddings(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d142324f8fcb46bbb5aa22bce8a1498f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>normalized_tweet_text</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "      <th>final_query</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>colB_sciB_marg05_scores</th>\n",
       "      <th>colB_sciB_marg05_topk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>covid recoveri studi usa reveal proport case e...</td>\n",
       "      <td>covid recoveri studi usa reveal proport case e...</td>\n",
       "      <td>[25aj8rj5, 66g5lpm6, o4vvlmr4, vmmwtdia, trrg1...</td>\n",
       "      <td>[32.9312629699707, 31.442752838134766, 31.2328...</td>\n",
       "      <td>[styavbvi, bqn29m9k, atji1xge, vymre7uv, trrg1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>\"among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>among 139 client expos two symptomat hair styl...</td>\n",
       "      <td>among 139 client expos two symptomat hair styl...</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, s2vckt2w, yrowv62k, g5hg3...</td>\n",
       "      <td>[45.07097625732422, 36.53841781616211, 40.1458...</td>\n",
       "      <td>[r58aohnu, icgsbelo, tgd6gy3z, s2vckt2w, ncayc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>i recall early on reading that researchers wor...</td>\n",
       "      <td>recal earli read research who examin coronavir...</td>\n",
       "      <td>recal earli read research who examin coronavir...</td>\n",
       "      <td>[mkwgkkoi, gruir7aw, xavegbty, vx1hjh26, ntxuf...</td>\n",
       "      <td>[23.75394630432129, 25.241092681884766, 25.281...</td>\n",
       "      <td>[sgo76prc, xavegbty, gruir7aw, l4o7nicc, ntxuf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>you know you're credible when national institu...</td>\n",
       "      <td>know your credibl nih websit paper 💃💃 someon p...</td>\n",
       "      <td>know your credibl nih websit paper 💃💃 someon p...</td>\n",
       "      <td>[3sr2exq9, sv48gjkk, tx8ypqsm, z795y51f, k0f4c...</td>\n",
       "      <td>[45.87574005126953, 42.32080841064453, 36.4390...</td>\n",
       "      <td>[3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, kca5r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>resistance to antifungal medications is a grow...</td>\n",
       "      <td>resist antifung medic grow issu global scope d...</td>\n",
       "      <td>resist antifung medic grow issu global scope d...</td>\n",
       "      <td>[ybwwmyqy, ouvq2wpq, rs3umc1x, sxx3yid9, vabb2...</td>\n",
       "      <td>[31.468902587890625, 29.60997200012207, 29.042...</td>\n",
       "      <td>[ybwwmyqy, vabb2f26, 3l6ipiwk, lzddnb8j, ouvq2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1395</th>\n",
       "      <td>14193</td>\n",
       "      <td>Residents at high risk of covid-19: effectiven...</td>\n",
       "      <td>0gn3b98n</td>\n",
       "      <td>residents at high risk of covid-19: effectiven...</td>\n",
       "      <td>resid high risk covid19 effect isol affect siz...</td>\n",
       "      <td>resid high risk covid19 effect isol affect siz...</td>\n",
       "      <td>[0gn3b98n, n5sei1oc, d8x3b9a3, wotf0lzx, 4sqjv...</td>\n",
       "      <td>[37.77806091308594, 31.755569458007812, 32.635...</td>\n",
       "      <td>[0gn3b98n, bwmpamea, ueb7mjnv, zqekxlz9, qpzg8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1396</th>\n",
       "      <td>14196</td>\n",
       "      <td>61% of teenagers hospitalized for covid were \"...</td>\n",
       "      <td>25bdifv6</td>\n",
       "      <td>61% of teenagers hospitalized for covid were \"...</td>\n",
       "      <td>61 teenag hospit covid extrem obes less 5 teen...</td>\n",
       "      <td>61 teenag hospit covid extrem obes less 5 teen...</td>\n",
       "      <td>[yhmcx7ae, s1gdbsfx, dq3qunwe, 0yysikc1, a1xjh...</td>\n",
       "      <td>[42.61531066894531, 40.86850357055664, 38.4249...</td>\n",
       "      <td>[cjmmwl2q, lpqdnuil, ocl5qf9o, yhmcx7ae, a1xjh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1397</th>\n",
       "      <td>14203</td>\n",
       "      <td>\"fresh evidence backing melatonin against covi...</td>\n",
       "      <td>qn6wawxk</td>\n",
       "      <td>\"fresh evidence backing melatonin against covi...</td>\n",
       "      <td>fresh evid back melatonin covid melatonin medi...</td>\n",
       "      <td>fresh evid back melatonin covid melatonin medi...</td>\n",
       "      <td>[qn6wawxk, dsz66r4u, b3ui95vx, 059oj76m, 7x1aj...</td>\n",
       "      <td>[36.224021911621094, 31.55619239807129, 32.542...</td>\n",
       "      <td>[qn6wawxk, wrsk5vh9, b3ui95vx, dsz66r4u, yk2th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>14233</td>\n",
       "      <td>the vaccine doesn't halt the spread, it is pro...</td>\n",
       "      <td>3u3i5myh</td>\n",
       "      <td>the vaccine doesn't halt the spread, it is pro...</td>\n",
       "      <td>vaccine doesnt halt spread proven allevi sympt...</td>\n",
       "      <td>vaccine doesnt halt spread proven allevi sympt...</td>\n",
       "      <td>[wt6azxc1, 25aj8rj5, uuxo3jk9, qh6fqna8, gtp5d...</td>\n",
       "      <td>[36.293182373046875, 32.04758071899414, 35.591...</td>\n",
       "      <td>[h9nzxlaf, 7368psat, y4m987yn, u66awao9, yx0u0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1399</th>\n",
       "      <td>14236</td>\n",
       "      <td>\"Great commentary from K. Carvalho,  black pre...</td>\n",
       "      <td>nih4l4ok</td>\n",
       "      <td>\"great commentary from k. carvalho, black preg...</td>\n",
       "      <td>great commentari k carvalho black pregnant wom...</td>\n",
       "      <td>great commentari k carvalho black pregnant wom...</td>\n",
       "      <td>[nih4l4ok, ndcg3o7a, ia8rou81, dfhxcqr8, rm6av...</td>\n",
       "      <td>[30.609100341796875, 25.939556121826172, 25.70...</td>\n",
       "      <td>[nih4l4ok, i5h0gm3u, y74qhqw7, y9kkl2lf, moplu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                         tweet_text  cord_uid  \\\n",
       "0          16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1          69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2          73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3          93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4          96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "...       ...                                                ...       ...   \n",
       "1395    14193  Residents at high risk of covid-19: effectiven...  0gn3b98n   \n",
       "1396    14196  61% of teenagers hospitalized for covid were \"...  25bdifv6   \n",
       "1397    14203  \"fresh evidence backing melatonin against covi...  qn6wawxk   \n",
       "1398    14233  the vaccine doesn't halt the spread, it is pro...  3u3i5myh   \n",
       "1399    14236  \"Great commentary from K. Carvalho,  black pre...  nih4l4ok   \n",
       "\n",
       "                                  normalized_tweet_text  \\\n",
       "0     covid recovery: this study from the usa reveal...   \n",
       "1     \"among 139 clients exposed to two symptomatic ...   \n",
       "2     i recall early on reading that researchers wor...   \n",
       "3     you know you're credible when national institu...   \n",
       "4     resistance to antifungal medications is a grow...   \n",
       "...                                                 ...   \n",
       "1395  residents at high risk of covid-19: effectiven...   \n",
       "1396  61% of teenagers hospitalized for covid were \"...   \n",
       "1397  \"fresh evidence backing melatonin against covi...   \n",
       "1398  the vaccine doesn't halt the spread, it is pro...   \n",
       "1399  \"great commentary from k. carvalho, black preg...   \n",
       "\n",
       "                                     cleaned_tweet_text  \\\n",
       "0     covid recoveri studi usa reveal proport case e...   \n",
       "1     among 139 client expos two symptomat hair styl...   \n",
       "2     recal earli read research who examin coronavir...   \n",
       "3     know your credibl nih websit paper 💃💃 someon p...   \n",
       "4     resist antifung medic grow issu global scope d...   \n",
       "...                                                 ...   \n",
       "1395  resid high risk covid19 effect isol affect siz...   \n",
       "1396  61 teenag hospit covid extrem obes less 5 teen...   \n",
       "1397  fresh evid back melatonin covid melatonin medi...   \n",
       "1398  vaccine doesnt halt spread proven allevi sympt...   \n",
       "1399  great commentari k carvalho black pregnant wom...   \n",
       "\n",
       "                                            final_query  \\\n",
       "0     covid recoveri studi usa reveal proport case e...   \n",
       "1     among 139 client expos two symptomat hair styl...   \n",
       "2     recal earli read research who examin coronavir...   \n",
       "3     know your credibl nih websit paper 💃💃 someon p...   \n",
       "4     resist antifung medic grow issu global scope d...   \n",
       "...                                                 ...   \n",
       "1395  resid high risk covid19 effect isol affect siz...   \n",
       "1396  61 teenag hospit covid extrem obes less 5 teen...   \n",
       "1397  fresh evid back melatonin covid melatonin medi...   \n",
       "1398  vaccine doesnt halt spread proven allevi sympt...   \n",
       "1399  great commentari k carvalho black pregnant wom...   \n",
       "\n",
       "                                              bm25_topk  \\\n",
       "0     [25aj8rj5, 66g5lpm6, o4vvlmr4, vmmwtdia, trrg1...   \n",
       "1     [r58aohnu, p0kg6dyz, s2vckt2w, yrowv62k, g5hg3...   \n",
       "2     [mkwgkkoi, gruir7aw, xavegbty, vx1hjh26, ntxuf...   \n",
       "3     [3sr2exq9, sv48gjkk, tx8ypqsm, z795y51f, k0f4c...   \n",
       "4     [ybwwmyqy, ouvq2wpq, rs3umc1x, sxx3yid9, vabb2...   \n",
       "...                                                 ...   \n",
       "1395  [0gn3b98n, n5sei1oc, d8x3b9a3, wotf0lzx, 4sqjv...   \n",
       "1396  [yhmcx7ae, s1gdbsfx, dq3qunwe, 0yysikc1, a1xjh...   \n",
       "1397  [qn6wawxk, dsz66r4u, b3ui95vx, 059oj76m, 7x1aj...   \n",
       "1398  [wt6azxc1, 25aj8rj5, uuxo3jk9, qh6fqna8, gtp5d...   \n",
       "1399  [nih4l4ok, ndcg3o7a, ia8rou81, dfhxcqr8, rm6av...   \n",
       "\n",
       "                                colB_sciB_marg05_scores  \\\n",
       "0     [32.9312629699707, 31.442752838134766, 31.2328...   \n",
       "1     [45.07097625732422, 36.53841781616211, 40.1458...   \n",
       "2     [23.75394630432129, 25.241092681884766, 25.281...   \n",
       "3     [45.87574005126953, 42.32080841064453, 36.4390...   \n",
       "4     [31.468902587890625, 29.60997200012207, 29.042...   \n",
       "...                                                 ...   \n",
       "1395  [37.77806091308594, 31.755569458007812, 32.635...   \n",
       "1396  [42.61531066894531, 40.86850357055664, 38.4249...   \n",
       "1397  [36.224021911621094, 31.55619239807129, 32.542...   \n",
       "1398  [36.293182373046875, 32.04758071899414, 35.591...   \n",
       "1399  [30.609100341796875, 25.939556121826172, 25.70...   \n",
       "\n",
       "                                  colB_sciB_marg05_topk  \n",
       "0     [styavbvi, bqn29m9k, atji1xge, vymre7uv, trrg1...  \n",
       "1     [r58aohnu, icgsbelo, tgd6gy3z, s2vckt2w, ncayc...  \n",
       "2     [sgo76prc, xavegbty, gruir7aw, l4o7nicc, ntxuf...  \n",
       "3     [3sr2exq9, k0f4cwig, sv48gjkk, 8j3bb6zx, kca5r...  \n",
       "4     [ybwwmyqy, vabb2f26, 3l6ipiwk, lzddnb8j, ouvq2...  \n",
       "...                                                 ...  \n",
       "1395  [0gn3b98n, bwmpamea, ueb7mjnv, zqekxlz9, qpzg8...  \n",
       "1396  [cjmmwl2q, lpqdnuil, ocl5qf9o, yhmcx7ae, a1xjh...  \n",
       "1397  [qn6wawxk, wrsk5vh9, b3ui95vx, dsz66r4u, yk2th...  \n",
       "1398  [h9nzxlaf, 7368psat, y4m987yn, u66awao9, yx0u0...  \n",
       "1399  [nih4l4ok, i5h0gm3u, y74qhqw7, y9kkl2lf, moplu...  \n",
       "\n",
       "[1400 rows x 9 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2) Finetuned BERT + MLP on matchmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchMatrixMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MatchMatrixMLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sim_matrix):\n",
    "        \"\"\"\n",
    "        sim_matrix: [q_len, d_len]\n",
    "        Returns: scalar score\n",
    "        \"\"\"\n",
    "\n",
    "        # Query-wise pooling\n",
    "        max_per_q = sim_matrix.max(dim=1).values  # [q_len]\n",
    "        mean_per_q = sim_matrix.mean(dim=1)\n",
    "        std_per_q = sim_matrix.std(dim=1)\n",
    "\n",
    "        # Document-wise pooling\n",
    "        max_per_d = sim_matrix.max(dim=0).values\n",
    "        mean_per_d = sim_matrix.mean(dim=0)\n",
    "        std_per_d = sim_matrix.std(dim=0)\n",
    "\n",
    "        # Global pooling\n",
    "        global_max = sim_matrix.max()\n",
    "        global_mean = sim_matrix.mean()\n",
    "        global_std = sim_matrix.std()\n",
    "\n",
    "        # Aggregate features\n",
    "        features = torch.tensor([\n",
    "            max_per_q.mean(), mean_per_q.mean(), std_per_q.mean(),\n",
    "            max_per_d.mean(), mean_per_d.mean(), std_per_d.mean(),\n",
    "            global_max, global_mean, global_std,\n",
    "            max_per_q.max(), max_per_d.max(), global_std\n",
    "        ], device=sim_matrix.device)\n",
    "\n",
    "        return self.mlp(features.unsqueeze(0)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matchmlp(\n",
    "    bert_model,\n",
    "    tokenizer,\n",
    "    metadata,\n",
    "    train_dataset,\n",
    "    device=\"cuda\",\n",
    "    epochs=5,\n",
    "    margin=0.3,\n",
    "    batch_size=8,\n",
    "    lr=2e-5\n",
    "):\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    match_model = MatchMatrixMLP().to(device)\n",
    "    bert_model.to(device).eval()\n",
    "    match_model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(match_model.parameters(), lr=lr)\n",
    "    triplet_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def sim_matrix(q, d):\n",
    "        q_norm = q / q.norm(dim=1, keepdim=True)\n",
    "        d_norm = d / d.norm(dim=1, keepdim=True)\n",
    "        return torch.matmul(q_norm, d_norm.T)  # [q_len, d_len]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(triplet_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "\n",
    "            # Encode queries\n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                q_output = bert_model(**inputs)\n",
    "\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [emb[mask] for emb, mask in zip(q_output.last_hidden_state, attention_mask)]\n",
    "\n",
    "            loss = 0.0\n",
    "            for i in range(len(queries)):\n",
    "                q_emb = q_embs[i]\n",
    "                d_pos = torch.load(metadata[pos_ids[i]][\"path\"]).to(device)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg = torch.load(metadata[neg_ids[i]][\"path\"]).to(device)[:metadata[neg_ids[i]][\"length\"]]\n",
    "\n",
    "                sim_pos = sim_matrix(q_emb, d_pos)\n",
    "                sim_neg = sim_matrix(q_emb, d_neg)\n",
    "\n",
    "                score_pos = match_model(sim_pos)\n",
    "                score_neg = match_model(sim_neg)\n",
    "\n",
    "                loss += F.relu(margin + score_neg - score_pos)\n",
    "\n",
    "            loss = loss / len(queries)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
    "\n",
    "    return match_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e2892eb744ed5a8d5533f0c766ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 718.9339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f211edc8ec41359c978c7e968c6837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 602.8695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a6adc1fdcf49da9bba6e0b322728d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 461.1193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5bf65dcb964479af80c6a85b0118d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 341.4806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b7567b4ffa49dfa208bbf19d85aab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 262.1859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c69fceaa7a46eba0baf07632ccd8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 212.2987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4269cdf09b54b70a1262c1e17e19704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 180.7391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c789ec2a624fccb60a20d1469fbc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 160.4647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700af6e07236430bb188cedaf788b28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 147.2528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c25bc3e4b74004ab188d476681208c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 138.4881\n"
     ]
    }
   ],
   "source": [
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "scibert_model = AutoModel.from_pretrained(model_name)\n",
    "train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer)\n",
    "\n",
    "mlp_model = train_matchmlp(\n",
    "    bert_model=scibert_model,\n",
    "    tokenizer=tokenizer,\n",
    "    metadata=metadata,\n",
    "    train_dataset=train_dataset,\n",
    "    device=\"cuda\",\n",
    "    epochs=10,\n",
    "    margin=0.5,\n",
    "    batch_size=8,\n",
    "    lr=2e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_mlp(df, metadata, tokenizer, bert_model, match_model, save_name):\n",
    "    device = next(bert_model.parameters()).device\n",
    "    bert_model.eval()\n",
    "    match_model.eval()\n",
    "\n",
    "    doc_embeddings = {\n",
    "        doc_id: torch.load(meta[\"path\"], map_location=device)[:meta[\"length\"]]\n",
    "        for doc_id, meta in metadata.items()\n",
    "    }\n",
    "\n",
    "    df[save_name + \"_scores\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            doc_ids = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, bert_model, device=device)\n",
    "            q_emb = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc_id in doc_ids:\n",
    "                d_emb = doc_embeddings[doc_id]\n",
    "                d_emb = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim = torch.matmul(q_emb, d_emb.T)  # [q_len, d_len]\n",
    "                score = match_model(sim).item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + \"_scores\"] = scores\n",
    "\n",
    "    df[save_name + \"_topk\"] = df.apply(\n",
    "        lambda row: [doc for doc, _ in sorted(\n",
    "            zip(row['bm25_topk'], row[save_name + '_scores']),\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee5129b95714ef6906c65dc7d76492e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reranked = rerank_with_cnn(\n",
    "    df=df_query_dev,\n",
    "    metadata=metadata,\n",
    "    tokenizer=tokenizer,\n",
    "    bert_model=scibert_model,\n",
    "    match_model=mlp_model,\n",
    "    save_name=\"sciB_mlp_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### 3.2) Finetuned BERT + CNN on matchmatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MatchPyramid(nn.Module):\n",
    "    def __init__(self, input_channels=1, conv_channels=16, pool_size=(6, 6)):\n",
    "        super(MatchPyramid, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, conv_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveMaxPool2d(pool_size)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_channels * pool_size[0] * pool_size[1], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sim_matrix):\n",
    "        # sim_matrix: [q_len, d_len]\n",
    "        x = sim_matrix.unsqueeze(0).unsqueeze(0)  # [1, 1, q_len, d_len]\n",
    "        x = self.conv(x)                          # [1, C, H, W]\n",
    "        x = self.pool(x)                          # [1, C, pool_H, pool_W]\n",
    "        score = self.mlp(x)                       # [1, 1]\n",
    "        return score.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matchpyramid(\n",
    "    bert_model,\n",
    "    tokenizer,\n",
    "    metadata,\n",
    "    train_dataset,\n",
    "    device=\"cuda\",\n",
    "    epochs=6,\n",
    "    margin=0.5,\n",
    "    batch_size=8,\n",
    "    lr=2e-5\n",
    "):\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model = MatchPyramid().to(device)\n",
    "    bert_model.to(device).eval()\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def get_sim(q, d):\n",
    "        q_norm = q / q.norm(dim=1, keepdim=True)\n",
    "        d_norm = d / d.norm(dim=1, keepdim=True)\n",
    "        return torch.matmul(q_norm, d_norm.T)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for queries, pos_ids, neg_ids in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = bert_model(**inputs)\n",
    "                attention_mask = inputs[\"attention_mask\"].bool()\n",
    "                q_embs = [o[mask] for o, mask in zip(output.last_hidden_state, attention_mask)]\n",
    "\n",
    "            loss = 0.0\n",
    "            for i in range(len(queries)):\n",
    "                q_emb = q_embs[i]\n",
    "                d_pos = torch.load(metadata[pos_ids[i]][\"path\"]).to(device)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg = torch.load(metadata[neg_ids[i]][\"path\"]).to(device)[:metadata[neg_ids[i]][\"length\"]]\n",
    "\n",
    "                sim_pos = get_sim(q_emb, d_pos)\n",
    "                sim_neg = get_sim(q_emb, d_neg)\n",
    "\n",
    "                score_pos = model(sim_pos)\n",
    "                score_neg = model(sim_neg)\n",
    "\n",
    "                loss += F.relu(margin + score_neg - score_pos)\n",
    "\n",
    "            loss = loss / len(queries)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7840a279744249b8f7b70b9f78c1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 341.4415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8e33e3e70c44be94dc4317054a5dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 161.8874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08715b988884b4a82eba23c4916c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 150.7042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2116545a0a734b09a6edddf6e89f5fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 144.8148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d73519ef74b53a6dbdcd7831cb365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 141.0205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9551c9d19894e9e8fcab9e30ca61dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 138.0958\n"
     ]
    }
   ],
   "source": [
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "scibert_model = AutoModel.from_pretrained(model_name)\n",
    "train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer)\n",
    "\n",
    "matchpyramid_model = train_matchpyramid(\n",
    "    bert_model=scibert_model,\n",
    "    tokenizer=tokenizer,\n",
    "    metadata=metadata,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_model.state_dict(), \"matchcnn_model_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_matchpyramid(df, metadata, tokenizer, bert_model, match_model, save_name):\n",
    "    device = next(bert_model.parameters()).device\n",
    "    bert_model.eval()\n",
    "    match_model.eval()\n",
    "\n",
    "    doc_embeddings = {\n",
    "        doc_id: torch.load(meta[\"path\"], map_location=device)[:meta[\"length\"]]\n",
    "        for doc_id, meta in metadata.items()\n",
    "    }\n",
    "\n",
    "    df[save_name + \"_scores\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            doc_ids = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, bert_model, device=device)\n",
    "            q_emb = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc_id in doc_ids:\n",
    "                d_emb = doc_embeddings[doc_id]\n",
    "                d_emb = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim = torch.matmul(q_emb, d_emb.T)\n",
    "                score = match_model(sim).item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + \"_scores\"] = scores\n",
    "\n",
    "    df[save_name + \"_topk\"] = df.apply(\n",
    "        lambda row: [doc for doc, _ in sorted(zip(row['bm25_topk'], row[save_name + '_scores']), key=lambda x: x[1], reverse=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = MatchCNN(input_size=32)\n",
    "cnn_model.load_state_dict(torch.load(\"matchcnn_model_1.pt\"))\n",
    "cnn_model.to(\"cuda\")\n",
    "cnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b293612dd7444f9dbe02d682ef948b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reranked = rerank_with_matchpyramid(\n",
    "    df=df_query_dev,\n",
    "    metadata=metadata,\n",
    "    tokenizer=tokenizer,\n",
    "    bert_model=scibert_model,\n",
    "    match_model=matchpyramid_model,\n",
    "    save_name=\"sciB_matchpyramid_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 4) Evaluation\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BM25 Baseline ----\n",
      "Results on the train set: {1: 0.5731735781529604, 5: 0.625250914183459, 10: 0.6308237901348459}\n",
      "Results on the dev set: {1: 0.5657142857142857, 5: 0.616095238095238, 10: 0.6224325396825396}\n"
     ]
    }
   ],
   "source": [
    "# ---- BM25 Baseline ----\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "\n",
    "print(\"---- BM25 Baseline ----\")\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune-4: ColBERT (SciBERT) ----\n",
      "MRR@5: 0.6806309523809524\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking (100 docs) @ Margin 0.5 ----\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.6758214285714286\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking (200 docs) @ Margin 0.5 ----\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.6803214285714285\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking (50 docs) @ Margin 0.5 ----\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.6775357142857142\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking (25 docs) @ Margin 0.5 ----\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.6532380952380952\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking @ Margin 0.6 ----\n",
    "model_name = \"colB_sciBERT_marg06\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.616095238095238\n"
     ]
    }
   ],
   "source": [
    "# ---- SciBERT + MLP Re-Ranking ----\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'sciB_mlp_1_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: ColBERT (SciBERT) ----\n",
      "MRR@5 on dev set: 0.5443095238095238\n"
     ]
    }
   ],
   "source": [
    "# ---- SciBERT + MLP Re-Ranking ----\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'sciB_matchpyramid_1_topk')\n",
    "print(\"---- Re-Ranking Finetune: ColBERT (SciBERT) ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results documentation\n",
    "\n",
    "### 1) SciBERT in ColBERT architecture\n",
    "Re-Ranking of top 50 BM25 results for each query:\n",
    "- SciBERT (ColBERT)\n",
    "    - used SciBERT model out of the box\n",
    "- SciBERT (ColBERT) @ 2EP\n",
    "    - fine tuned SciBERT in 2 epochs on train data\n",
    "- SciBERT (ColBERT) @ 4EP\n",
    "    - based on previous fine tune (SciBERT (ColBERT) @ 2EP), fine tuned SciBERT in additional 2 epochs, resulting in 4 epochs fine tune compared to out of the box SciBERT\n",
    "- SciBERT (ColBERT) @ 8EP\n",
    "    - based on previous fine tune (SciBERT (ColBERT) @ 4EP), fine tuned SciBERT in additional 4 epochs, resulting in 8 epochs fine tune compared to out of the box SciBERT\n",
    "\n",
    "Hyperparameters:\n",
    "- BATCH_SIZE = 8\n",
    "- LR = 2e-5\n",
    "- MARGIN = 0.2\n",
    "\n",
    "Loss Function: <br>\n",
    "loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "|Model                        | MRR@5 (dev)     |\n",
    "|-----------------------------|-----------------|\n",
    "|BM25 (baseline)              |55.20%           |\n",
    "|SciBERT (ColBERT)            |56.94%           | \n",
    "|SciBERT (ColBERT) @ 2EP      |63.51%           |\n",
    "|SciBERT (ColBERT) @ 4EP      |64.02%           |\n",
    "|SciBERT (ColBERT) @ 8EP      |62.26%           |\n",
    "\n",
    "#### 1.1) Grid search for finding best margin and number of negative samples\n",
    "| Margin | Negatives | MRR@5     | Last Epoch Loss |\n",
    "|--------|-----------|-----------|--------------|\n",
    "| 0.3    | 1         | 0.6537    | 8.0212       |\n",
    "| 0.3    | 2         | 0.6477    | 16.7373      |\n",
    "| 0.3    | 4         | 0.6118    | 29.3307      |\n",
    "| 0.4    | 1         | 0.6574    | 12.9181      |\n",
    "| 0.4    | 2         | 0.6503    | 21.4273      |\n",
    "| 0.4    | 4         | 0.6360    | 27.8490      |\n",
    "| **0.5**    | **1**         | **0.6610**    | **9.6190**       |\n",
    "| 0.5    | 2         | 0.6393    | 18.1380      |\n",
    "| 0.5    | 4         | 0.6259    | 31.5070      |\n",
    "\n",
    "For margin 0.6 MRR@5 goes down again: 0.6532"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 5) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "df_query_test['preds'] = df_query_test[f'{model_name}_topk'].apply(lambda x: x[:5])\n",
    "df_query_test[\"post_id\"] = df_query_test[\"post_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_test[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## _) Archive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search for best parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out different combinations of margin and number of negative document samples for training. <br>\n",
    "Result: **margin of 0.5** seems to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Combination 1/9 → colB_sciB_m3_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e09fd20c50d409ebe8b5d34d2509a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 121.9535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce646d659fb4e41b08da114668cbaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 40.3961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7006d7f1386a415097e935b7caabf68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 23.0165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd8b1e60ce547c28be5201422780adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 12.7019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9d31848ba8425192565230a9a06a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 7.5942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6b108b62d7450c95fea059f8215ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 8.0212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434f634c3cd24aec8b6bcbd9cc159524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa40856f46154657ac80b44ffc783e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6537142857142857\n",
      "\n",
      "🔍 Combination 2/9 → colB_sciB_m3_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b25f30c0936409fb0fbb0dcdd7401fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 198.2437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91809150dd6e432489c4d4ae3f51766f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 72.1588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427c256ec2d64d46b75eaa459975ba7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 46.9973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40265b6e4e114bb28f3e837fbad949dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 28.1074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98ebe27ef4c4702a8c3c9d0be795069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 23.5954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccacc3304416419aae3e09b1ca095ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 16.7373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a73804eaf94e679dab3916598549d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b5ad6ecad14b73b81c3696a13a008e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6477142857142858\n",
      "\n",
      "🔍 Combination 3/9 → colB_sciB_m3_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6604e85353f4c1a96259cadd04081e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 352.6436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bf50ff4c047499d2dfb370889d950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 134.0740\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e271355e337447288da685f9b87b7973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 63.8498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78562c0afd264b4584e06c645241410c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 42.9125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09550471fdbe4919b96ff06abdd36478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 31.2010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9277c4e6eb546dd863ff12062d79515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 29.3307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4115a60c084d6395f46b080e7fd6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2360f807306d40b89a8fc0ba1090fb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6118333333333333\n",
      "\n",
      "🔍 Combination 4/9 → colB_sciB_m4_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593927cd5bca4ca3ac111a150d9b53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 137.3641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57159f0497db4ae4ad6d36681103cac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 52.0689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e20806081b4f37b21276934af8b242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 23.6070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944a5737a791440a914e9b5d11d54e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 17.4979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b31d92c4e34faf9b43a4dd3611b5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 9.9772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeafdd544164f73858f00e68a63d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 12.9181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98e12e3bcf8477fae34ef1e10415b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb2ada83d4e45faadb6c6d5624716c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6574285714285714\n",
      "\n",
      "🔍 Combination 5/9 → colB_sciB_m4_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ddde22bf034ba98eaeccb4fe279cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 227.4885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e6a8f8fbbd43598593fa5926d2b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 92.5719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617c1746f60642bd971136494b77f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 51.2666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef09260d944427b93542f1894133e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 30.8887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac6e855bac04f9ebb710b8d465f8f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 23.0024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b193e5ef064a5eafa9104ed9f9905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 21.4273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce41852813a4b42963c1e89c6ec7768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47536aeb7564a889d467e9bee1ef001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6502738095238095\n",
      "\n",
      "🔍 Combination 6/9 → colB_sciB_m4_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc0f00d8674524a4c54db1c280d060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 359.6384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c4f4165e174428abdd3251ec323e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 131.8794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bce1c803e545c5a5a1c4bfce51dc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 63.0106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db41e5652b449cd8feb4ed1cf6b9ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 50.9670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653aca41aac94923a2b5abff30e99165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 38.3159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc814c63b0741179b9ffafc0160d6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 27.8490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b82887947f449b88699c1135c500131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e8595fee134e92a18585517abb9b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6360357142857143\n",
      "\n",
      "🔍 Combination 7/9 → colB_sciB_m5_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e8abe7a3b475d824558eb9512204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 160.1443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7de1ecf5214502a22416d6282d2b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 65.4520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e46e209ea454d08b9cc42b2ecf33f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 29.0368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa0fc891e9434a94f198165c36d72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 29.2456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e2d964e5d458aa9b0c251ca8cef50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 15.5198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da3178ba6a8410b9e637e6fa5752e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 9.6190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8d828954cc4db39e478692e6ccd77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9106981208d4bbd9057d9294488308c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6610238095238096\n",
      "\n",
      "🔍 Combination 8/9 → colB_sciB_m5_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66b958180604afbbae332786422c136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 257.0342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58015fc0f4274bb59808c8af376bf9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 89.1174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba91ac191984cd4bfb8bc659b1c3556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 41.8070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fc8466afb24a0c9c22d200ea70d180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 29.2456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2a5703f7ef4c45acc8809d3904d341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 21.2743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1c5421d9bd42fcafc5d75ec2080b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 18.1380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbfaaf3b73b43de902d88bcf4c6b107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d493c1b3b046b8b3878cbd77466f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.639345238095238\n",
      "\n",
      "🔍 Combination 9/9 → colB_sciB_m5_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81e1017b6c64e53901d6bc61540cd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 395.6334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc07155334146f387fa3a27d7e95942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 110.6216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c71da866c4fadbec85a2ede4b2b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 54.9982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eca26adc2b49649f7c278260ccf9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 41.8254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df868072a7840d8b75f19ff664b015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 32.5702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ef41191df1453dbb31ecbedb0c7a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 31.5070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a44c1bb14884babb2160e056665fbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2638ace67ba542a3b901180dcb591135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6259285714285714\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import random, torch, numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"margin\":        [0.3, 0.4, 0.5],\n",
    "    \"num_negatives\": [1, 2, 4]\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "for i, (margin, num_neg) in enumerate(product(*values), 1):\n",
    "    set_seed()\n",
    "    model_name = f\"colB_sciB_m{str(margin)[-1]}_neg{num_neg}\"\n",
    "    print(f\"\\n🔍 Combination {i}/9 → {model_name}\")\n",
    "\n",
    "    scibert_finetune(\n",
    "        save_name      = model_name,\n",
    "        MARGIN         = margin,\n",
    "        BATCH_SIZE     = 8,\n",
    "        EPOCHS         = 6,\n",
    "        LR             = 2e-5,\n",
    "        num_negatives  = num_neg\n",
    "    )\n",
    "\n",
    "    # ---------- Evaluation ----------\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model     = AutoModel.from_pretrained(model_name)\n",
    "    metadata  = pre_compute_embeddings(model_name)\n",
    "\n",
    "    df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, model_name)\n",
    "    mrr_scores   = get_performance_mrr(df_query_dev, \"cord_uid\", f\"{model_name}_topk\")\n",
    "    print(\"MRR@5:\", mrr_scores[5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1) Baseline: ColBERT architecture with SciBERT\n",
    "Use a pretrained SciBERT model to:\n",
    "- embed each query-token\n",
    "- embed each doc-token (can be pre-computed)\n",
    "\n",
    "For each query-doc pair:\n",
    "- calculate match-matrix: each query-token – doc-token pair gets cosine similarity value\n",
    "- aggregate the score: \n",
    "    - for each query-token take max cosine similarity value with corresponding doc-tokens\n",
    "    - sum over all of the max elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    max_len=512,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        output = model(**inputs)\n",
    "        token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "        token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cuda(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Speichern von {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_compute_embeddings(save_name):\n",
    "    if not os.path.exists(\"doc_embeddings_\" + save_name + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, model_name=model_name, save_dir=save_name, device=\"cuda\")\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, model, save_name):\n",
    "    device = next(model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model).to(device)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "# settings for model run:\n",
    "model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "save_name = \"scibert_baseline\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre-compute embeddings\n",
    "metadata = pre_compute_embeddings(save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-rank BM25 list for train data\n",
    "df_query_train = rerank(df_query_train, metadata, tokenizer, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ColBERT w/ fine-tuned SciBERT for docs and CTBERT for queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "\n",
    "# hyperparameter\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 4\n",
    "LR = 2e-5\n",
    "MARGIN = 0.2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load model\n",
    "query_model_name = \"digitalepidemiologylab/covid-twitter-bert\"\n",
    "doc_model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "query_tokenizer = AutoTokenizer.from_pretrained(query_model_name)\n",
    "doc_tokenizer = AutoTokenizer.from_pretrained(doc_model_name)\n",
    "\n",
    "query_model = AutoModel.from_pretrained(query_model_name).to(DEVICE)\n",
    "doc_model = AutoModel.from_pretrained(doc_model_name).to(DEVICE)\n",
    "\n",
    "# projection to same dimensions\n",
    "query_projection = nn.Linear(1024, 768).to(DEVICE)\n",
    "\n",
    "# dataset creation\n",
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# helper functions\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    return token_embeddings[attention_mask]\n",
    "\n",
    "def get_doc_embedding(doc_id, metadata, tokenizer, model, device):\n",
    "    text = f\"{metadata[doc_id]['title']} {metadata[doc_id]['abstract']} Authors: {metadata[doc_id]['authors']}\"\n",
    "    return get_token_embeddings(text, tokenizer, model, device)\n",
    "\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    return sim_matrix.max(dim=1).values.sum()\n",
    "\n",
    "# training function\n",
    "def train_colbert_dual_encoder(df_query_train, metadata):\n",
    "    dataset = ColBERTTripletDataset(df_query_train, metadata)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    query_model.train()\n",
    "    doc_model.train()\n",
    "    query_projection.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        list(query_model.parameters()) +\n",
    "        list(doc_model.parameters()) +\n",
    "        list(query_projection.parameters()),\n",
    "        lr=LR\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "\n",
    "            inputs = query_tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = query_model(**inputs)\n",
    "            q_emb_batch = outputs.last_hidden_state\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [query_projection(emb[mask]) for emb, mask in zip(q_emb_batch, attention_mask)]\n",
    "\n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "\n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = get_doc_embedding(pos_ids[i], metadata, doc_tokenizer, doc_model, DEVICE)\n",
    "                d_neg_emb = get_doc_embedding(neg_ids[i], metadata, doc_tokenizer, doc_model, DEVICE)\n",
    "                q_emb = q_embs[i]\n",
    "\n",
    "                score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "                score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "\n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "\n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "\n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    query_model.save_pretrained(\"finetuned_ctbert\")\n",
    "    query_tokenizer.save_pretrained(\"finetuned_ctbert\")\n",
    "    doc_model.save_pretrained(\"finetuned_scibert\")\n",
    "    doc_tokenizer.save_pretrained(\"finetuned_scibert\")\n",
    "    torch.save(query_projection.state_dict(), \"query_projection.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_colbert_dual_encoder(df_query_train, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, q_model, d_model, save_name):\n",
    "    device_q = next(q_model.parameters()).device\n",
    "    device_d = next(d_model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    query_projection = nn.Linear(1024, 768)\n",
    "    query_projection.load_state_dict(torch.load(\"query_projection.pt\"))\n",
    "    query_projection.to(device_q)\n",
    "    query_projection.eval()\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, q_model, device=device_q)\n",
    "            q_emb = query_projection(q_emb)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device_d)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7718/7718 [03:40<00:00, 34.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# pre-compute embeddings\n",
    "metadata = pre_compute_embeddings(\"finetuned_scibert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1400/1400 [02:21<00:00,  9.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, query_model, doc_model, \"sciCtBERT-1\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
