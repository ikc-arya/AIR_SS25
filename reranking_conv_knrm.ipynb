{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "Requirement already satisfied: pandarallel in /opt/conda/lib/python3.11/site-packages (1.6.5)\n",
      "Requirement already satisfied: rank_bm25 in /opt/conda/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: dill>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from pandarallel) (0.3.9)\n",
      "Requirement already satisfied: pandas>=1 in /opt/conda/lib/python3.11/site-packages (from pandarallel) (2.2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from pandarallel) (5.9.8)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1->pandarallel) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1->pandarallel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1->pandarallel) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pandarallel import pandarallel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing query and collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask_4b/subtask4b_collection_data.pkl' \n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "PATH_QUERY_TRAIN_DATA = 'subtask_4b/subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask_4b/subtask4b_query_tweets_dev.tsv' \n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP"
   },
   "source": [
    "# 2) Running the BM25 baseline\n",
    "The following code runs a BM25 baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:100] # @k: how many docs shall the ranked list include?\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top100 candidates using the BM25 model\n",
    "\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "if not os.path.exists(train_pkl_path):\n",
    "    df_query_train['bm25_topk'] = df_query_train['tweet_text'].parallel_apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_train.to_pickle(train_pkl_path)\n",
    "else:\n",
    "    df_query_train = pd.read_pickle(train_pkl_path)\n",
    "\n",
    "if not os.path.exists(dev_pkl_path):\n",
    "    df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].parallel_apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_dev.to_pickle(dev_pkl_path)\n",
    "else:\n",
    "    df_query_dev = pd.read_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>normalized_tweet_text</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "      <th>final_query</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>oral care rehabilit medicin oral vulner oral m...</td>\n",
       "      <td>oral care rehabilit medicin oral vulner oral m...</td>\n",
       "      <td>[htlvpvz5, h7hj64q5, trmwm9qq, 65gedo6u, rwgqk...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>studi isnt receiv suffici attent reveal blackl...</td>\n",
       "      <td>studi isnt receiv suffici attent reveal blackl...</td>\n",
       "      <td>[apqzyln2, asdcpvhx, 33znyrn8, ljcdfmbu, 296il...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>thank xi jinp remind studi conclud nonpharmace...</td>\n",
       "      <td>thank xi jinp remind studi conclud nonpharmace...</td>\n",
       "      <td>[jtwb17u8, veeavho5, mwj0xc3q, 8hkxbxz9, a0q61...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "      <td>taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>taiwan popul 23 million 600 case 7 death wides...</td>\n",
       "      <td>taiwan popul 23 million 600 case 7 death wides...</td>\n",
       "      <td>[lsgm7y5t, l5ogbl5p, l4y7v729, x14iywtr, 0w9k8...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "      <td>obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>obtain diagnosi autism lower incom countri tak...</td>\n",
       "      <td>obtain diagnosi autism lower incom countri tak...</td>\n",
       "      <td>[tiqksd69, b0dzhsrh, k7smwz6w, aqbhxv1f, 0u330...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5   \n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul   \n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8   \n",
       "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1   \n",
       "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69   \n",
       "\n",
       "                               normalized_tweet_text  \\\n",
       "0  oral care in rehabilitation medicine: oral vul...   \n",
       "1  this study isn't receiving sufficient attentio...   \n",
       "2  thanks, xi jinping. a reminder that this study...   \n",
       "3  taiwan - a population of 23 million has had ju...   \n",
       "4  obtaining a diagnosis of autism in lower incom...   \n",
       "\n",
       "                                  cleaned_tweet_text  \\\n",
       "0  oral care rehabilit medicin oral vulner oral m...   \n",
       "1  studi isnt receiv suffici attent reveal blackl...   \n",
       "2  thank xi jinp remind studi conclud nonpharmace...   \n",
       "3  taiwan popul 23 million 600 case 7 death wides...   \n",
       "4  obtain diagnosi autism lower incom countri tak...   \n",
       "\n",
       "                                         final_query  \\\n",
       "0  oral care rehabilit medicin oral vulner oral m...   \n",
       "1  studi isnt receiv suffici attent reveal blackl...   \n",
       "2  thank xi jinp remind studi conclud nonpharmace...   \n",
       "3  taiwan popul 23 million 600 case 7 death wides...   \n",
       "4  obtain diagnosi autism lower incom countri tak...   \n",
       "\n",
       "                                           bm25_topk  in_topx  \n",
       "0  [htlvpvz5, h7hj64q5, trmwm9qq, 65gedo6u, rwgqk...      1.0  \n",
       "1  [apqzyln2, asdcpvhx, 33znyrn8, ljcdfmbu, 296il...      0.0  \n",
       "2  [jtwb17u8, veeavho5, mwj0xc3q, 8hkxbxz9, a0q61...      1.0  \n",
       "3  [lsgm7y5t, l5ogbl5p, l4y7v729, x14iywtr, 0w9k8...      0.2  \n",
       "4  [tiqksd69, b0dzhsrh, k7smwz6w, aqbhxv1f, 0u330...      1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) BERT Embeddings pre-computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gonna run pytorch on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Gonna run pytorch on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings of a specified text passage from some model\n",
    "def get_token_embeddings(text, tokenizer, model, device):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "# pre compute all the token embeddings of the documents\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    device,\n",
    "    max_len=512,\n",
    "    batch_size=16\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    \n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "    \n",
    "    print(\"Precomputing document embeddings.\")\n",
    "    \n",
    "    texts = []\n",
    "    doc_ids = []\n",
    "    indices = []\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "        texts.append(text)\n",
    "        doc_ids.append(doc_id)\n",
    "        indices.append(i)\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(texts), batch_size), total=len(texts), desc=\"Saving doc embeddings\"):\n",
    "        end_idx = min(start_idx + batch_size, len(texts))\n",
    "        batch_texts = texts[start_idx:end_idx]\n",
    "        batch_doc_ids = doc_ids[start_idx:end_idx]\n",
    "\n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=max_len).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        q_emb_batch = outputs.last_hidden_state  # [batch_size, L, D]\n",
    "        attention_mask = inputs['attention_mask'].to(torch.bool)\n",
    "        \n",
    "        for i in range(len(batch_texts)):\n",
    "            att_mask = attention_mask[i]\n",
    "            embeddings = q_emb_batch[i][att_mask]\n",
    "            doc_id = batch_doc_ids[i]\n",
    "\n",
    "            file_path = Path(f\"doc_embeddings_{save_dir}\") / f\"{doc_id}.pt\"\n",
    "            torch.save(embeddings, file_path)\n",
    "            n_tokens = embeddings.shape[0]\n",
    "\n",
    "            if doc_id not in metadata:\n",
    "                metadata[doc_id] = {\n",
    "                    \"length\": min(n_tokens, max_len),\n",
    "                    \"path\": str(file_path)\n",
    "                }\n",
    "\n",
    "    metadata_path = Path(f\"doc_embeddings_{save_dir}\") / \"metadata.json\"\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# either precompute or load precomputed doc embeddings\n",
    "def get_precomputed_doc_embeddings(save_name):\n",
    "    def split_at_slash(s):\n",
    "        if '/' in s:\n",
    "            return s.split('/', 1)\n",
    "        else:\n",
    "            return ['', s]\n",
    "        \n",
    "    if not os.path.exists(\"doc_embeddings_\" + split_at_slash(save_name)[1] + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, \"allenai/scibert_scivocab_uncased\", save_name, DEVICE)\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "doc_embeddings_allenai = get_precomputed_doc_embeddings(\"allenai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings_allenai = {\n",
    "    k: {'length': v['length'], 'path': v['path'].replace('all_embeddings', 'allenai')}\n",
    "    for k, v in doc_embeddings_allenai.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Neural Re-Ranking with Conv-KNRM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create interface for generating convolutional layers for n-grams, calculate the similarity match matrix, generating kernel pooling object and the reranking function itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Define the neural network, train and rerank functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### NGram Convolutional Layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramConvLayer(nn.Module):\n",
    "    def __init__(self, input_dim, out_channels, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv_q = nn.Conv1d(input_dim, out_channels, kernel_size, padding=kernel_size//2)\n",
    "        self.conv_d = nn.Conv1d(input_dim, out_channels, kernel_size, padding=kernel_size//2)\n",
    "\n",
    "    def forward(self, q_emb, d_emb):\n",
    "        q_emb_conv = q_emb.transpose(0, 1).unsqueeze(0)  # [1, D, L_q]\n",
    "        d_emb_conv = d_emb.transpose(0, 1).unsqueeze(0)  # [1, D, L_d]\n",
    "\n",
    "        q_conv = F.relu(self.conv_q(q_emb_conv)).transpose(1, 2)  # [1, L_q, out_channels]\n",
    "        d_conv = F.relu(self.conv_d(d_emb_conv)).transpose(1, 2)  # [1, L_d, out_channels]\n",
    "\n",
    "        return q_conv.squeeze(0), d_conv.squeeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Kernel Pooling Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPooling(nn.Module):\n",
    "    def __init__(self, _mus, _sigmas):\n",
    "        super().__init__()\n",
    "        self.mus = torch.tensor(_mus).view(1, -1).to(DEVICE)  # shape: [1, num_kernels]\n",
    "        self.sigmas = torch.tensor(_sigmas).view(1, -1).to(DEVICE)\n",
    "\n",
    "    def forward(self, sim_matrix):\n",
    "        # sim_matrix: [L_q, L_d]\n",
    "        sim_matrix = sim_matrix.unsqueeze(0).unsqueeze(0)  # [1,1,L_q,L_d]\n",
    "        kernel_vals = torch.exp(- (sim_matrix - self.mus.reshape(1, -1, 1, 1))**2 / (2 * self.sigmas.reshape(1, -1, 1, 1)**2))\n",
    "        pooled = kernel_vals.sum(dim=3).sum(dim=2)  # shape: [1, num_kernels]\n",
    "        return pooled.squeeze(0)  # shape: [num_kernels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNRM Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_similarity_matrix(q_embs, d_embs):\n",
    "    q_norm = F.normalize(q_embs, p=2, dim=1)\n",
    "    d_norm = F.normalize(d_embs, p=2, dim=1)\n",
    "    return torch.mm(q_norm, d_norm.T).to(DEVICE)\n",
    "\n",
    "class KNRM(nn.Module):\n",
    "    def __init__(self, _mus, _sigmas, use_conv, conv_channels=8, ngram_size=1):\n",
    "        super().__init__()\n",
    "        self.kernel_pool = KernelPooling(_mus, _sigmas)\n",
    "        if use_conv:\n",
    "            self.conv_layer = NGramConvLayer(input_dim=768, out_channels=conv_channels, kernel_size=ngram_size)\n",
    "        else:\n",
    "            self.conv_layer = None\n",
    "\n",
    "        num_kernels = len(_mus)\n",
    "        feature_dim = num_kernels * (conv_channels if use_conv else 1)\n",
    "        self.scorer = nn.Linear(feature_dim, 1)\n",
    "\n",
    "    def forward(self, q_emb, d_emb):\n",
    "        if self.conv_layer:\n",
    "            q_conv, d_conv = self.conv_layer(q_emb, d_emb)\n",
    "            \n",
    "            channels = q_conv.shape[1]\n",
    "            all_features = []\n",
    "            \n",
    "            for c in range(channels):\n",
    "                q_c = q_conv[:, c].unsqueeze(1)  # [L_q, 1]\n",
    "                d_c = d_conv[:, c].unsqueeze(1)  # [L_d, 1]\n",
    "                \n",
    "                sim_c = compute_similarity_matrix(q_c, d_c)\n",
    "                \n",
    "                features_c = self.kernel_pool(sim_c)  # [num_kernels]\n",
    "                all_features.append(features_c)\n",
    "            \n",
    "            pooled_features = torch.cat(all_features, dim=0)  # [num_kernels * channels]\n",
    "        else:\n",
    "            sim_matrix = compute_similarity_matrix(q_emb, d_emb)\n",
    "            pooled_features = self.kernel_pool(sim_matrix)\n",
    "        score = self.scorer(pooled_features)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### KNRM Triplet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNRMTripletDataset(Dataset):\n",
    "    def __init__(self, df_query, metadata, tokenizer, num_negatives=1):\n",
    "        self.queries = []\n",
    "        self.pos_ids = []\n",
    "        self.neg_ids = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.metadata = metadata\n",
    "        \n",
    "        for _, row in df_query.iterrows():\n",
    "            query = row['tweet_text']\n",
    "            pos_id = row['cord_uid']\n",
    "            candidates = row['bm25_topk']\n",
    "            neg_candidates = [doc for doc in candidates if doc != pos_id]\n",
    "            \n",
    "            if neg_candidates:\n",
    "                neg_ids = random.sample(neg_candidates, min(num_negatives, len(neg_candidates)))\n",
    "                for neg_id in neg_ids:\n",
    "                    self.queries.append(query)\n",
    "                    self.pos_ids.append(pos_id)\n",
    "                    self.neg_ids.append(neg_id)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.queries[idx], self.pos_ids[idx], self.neg_ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNRM training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knrm_train(mus, sigmas, use_conv, ngram_size, save_name, MARGIN=0.5, BATCH_SIZE=8, EPOCHS=6, LR=1e-3):\n",
    "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    bert_model = AutoModel.from_pretrained(model_name).to(DEVICE)\n",
    "    knrm = KNRM(mus, sigmas, use_conv, ngram_size=ngram_size).to(DEVICE)\n",
    "    metadata = get_precomputed_doc_embeddings(model_name)\n",
    "\n",
    "    train_dataset = KNRMTripletDataset(df_query_train, metadata, tokenizer)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(knrm.parameters(), lr=LR)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "            \n",
    "            q_embs = []\n",
    "            for query in queries:\n",
    "                q_emb = get_token_embeddings(query, tokenizer, bert_model, DEVICE)\n",
    "                q_embs.append(q_emb)\n",
    "\n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "\n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(DEVICE)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(DEVICE)[:metadata[neg_ids[i]][\"length\"]]\n",
    "\n",
    "                score_pos = knrm(q_embs[i], d_pos_emb)\n",
    "                score_neg = knrm(q_embs[i], d_neg_emb)\n",
    "\n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "\n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "\n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    torch.save(knrm.state_dict(), f\"{save_name}.pt\")\n",
    "    return knrm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Embeddings Caching Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsLoader:\n",
    "    doc_embeddings = {}\n",
    "\n",
    "    @classmethod\n",
    "    def get_embeddings(cls):\n",
    "        if cls.doc_embeddings:\n",
    "            return cls.doc_embeddings\n",
    "        else:\n",
    "            for doc_id, data in tqdm(doc_embeddings_allenai.items(), desc=\"loading_doc_embeddings\"):\n",
    "                emb = torch.load(data[\"path\"], map_location=DEVICE)\n",
    "                cls.doc_embeddings[doc_id] = emb\n",
    "            return cls.doc_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Reranking function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, knrm_model_name, knrm_model_instance, device):\n",
    "    df[f'{knrm_model_name}_scores'] = [[]] * len(df)\n",
    "\n",
    "    knrm_model_instance = knrm_model_instance.to(device)\n",
    "    knrm_model_instance.load_state_dict(torch.load(f\"{knrm_model_name}.pt\"))\n",
    "    knrm_model_instance.eval()\n",
    "\n",
    "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc='calculating_scores_for_reranking'):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model, device=device)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = EmbeddingsLoader().get_embeddings()[doc]\n",
    "                length = doc_embeddings_allenai[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "\n",
    "                score = knrm_model_instance(q_emb, d_emb).item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, f'{knrm_model_name}_scores'] = scores\n",
    "\n",
    "        def sort_docs_by_score(row):\n",
    "            doc_ids = row['bm25_topk']\n",
    "            scores = row[f'{knrm_model_name}_scores']\n",
    "            sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "            return sorted_docs\n",
    "\n",
    "        df[f'{knrm_model_name}_topk'] = df.parallel_apply(sort_docs_by_score, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluation of different knrm models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1 Plain KNRM with 1-grams and 3 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d05a9d37e0294e29a53684d25d2ebc9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1347c0306e1c4a21aaa02737b59f3367",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23780998fd6e4e3c89c0e02087423825",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 12846.5115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd5a8f7eca0f4690a952a423eb476fd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 714.3910\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ed26121c6b4c9aa5a065edf7e3bc46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 745.6552\n"
     ]
    }
   ],
   "source": [
    "mus = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "sigmas = [0.1] * len(mus)\n",
    "use_conv = False\n",
    "ngram_size = 1\n",
    "KNRM_MODEL_NAME = \"knrm\"\n",
    "EPOCHS = 3\n",
    "\n",
    "knrm_model = knrm_train(mus, sigmas, use_conv=use_conv, ngram_size=ngram_size, save_name=KNRM_MODEL_NAME, EPOCHS=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e36917c3916443b9a40a3cf70f5de594",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating_scores_for_reranking:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e0d91268bd4f6eb1bfc9bf66020cd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading_doc_embeddings:   0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00b3f1b8e3e8453983b8b988d73dc0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=88), Label(value='0 / 88'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: KNRM ----\n",
      "MRR@5 on dev set: 0.36279761904761904\n"
     ]
    }
   ],
   "source": [
    "reranked_knrm_query_dev_df = rerank(df_query_dev, KNRM_MODEL_NAME, knrm_model, DEVICE)\n",
    "reranked_knrm_query_dev_df.head()\n",
    "\n",
    "# ---- KNRM Re-Ranking ----\n",
    "results_dev = get_performance_mrr(reranked_knrm_query_dev_df, 'cord_uid', f'{KNRM_MODEL_NAME}_topk')\n",
    "print(\"---- Re-Ranking Finetune: KNRM ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 Conv-KNRM with 1-grams and 3 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f52c31aa604f46a290ede72be07ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8382706fb96d433590f3d62f8a66d942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae813ac400d43df92378804d4ad9221",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 39152.5070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da88f8d4a0b44bab9623fc8dbe62bcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 8364.2339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cfa06c5b4b8476fb6f885596b083f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 8031.9155\n"
     ]
    }
   ],
   "source": [
    "mus = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "sigmas = [0.1] * len(mus)\n",
    "use_conv = True\n",
    "ngram_size = 1\n",
    "CONV_KNRM_MODEL_NAME = \"conv_knrm\"\n",
    "EPOCHS = 3\n",
    "\n",
    "conv_knrm_model = knrm_train(mus, sigmas, use_conv=use_conv, ngram_size=ngram_size, save_name=CONV_KNRM_MODEL_NAME, EPOCHS=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3a82277e5ea4fd98488028782dff9d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating_scores_for_reranking:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0698bd2c1104a289222d184a941d5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loading_doc_embeddings:   0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adb7c9d5a1a146228a5cca0e7c4d5fb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=88), Label(value='0 / 88'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: Conv-KNRM 1-gram ----\n",
      "MRR@5 on dev set: 0.03085714285714286\n"
     ]
    }
   ],
   "source": [
    "reranked_conv_knrm_query_dev_df = rerank(df_query_dev, CONV_KNRM_MODEL_NAME, conv_knrm_model, DEVICE)\n",
    "reranked_conv_knrm_query_dev_df.head()\n",
    "\n",
    "# ---- Conv-KNRM with 1-gram Re-Ranking ----\n",
    "results_dev = get_performance_mrr(reranked_conv_knrm_query_dev_df, 'cord_uid', f'{CONV_KNRM_MODEL_NAME}_topk')\n",
    "print(\"---- Re-Ranking Finetune: Conv-KNRM 1-gram ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 Conv-KNRM with Bigrams and 3 epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "767e7c2d6f6f402fb1123c62e992d4b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4783eb396d64665a575e41fc5c7d6f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fce788294347a7895084b650862306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 72564.8783\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea3dc7f8da824a4f853f14b58c3b2833",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 9399.7255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72da85a612a4485e883cb407f08ee9fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 8109.0142\n"
     ]
    }
   ],
   "source": [
    "mus = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "sigmas = [0.1] * len(mus)\n",
    "use_conv = True\n",
    "ngram_size = 2\n",
    "CONV_KNRM_BIGRAM_MODEL_NAME = \"conv_knrm_bigram\"\n",
    "EPOCHS = 3\n",
    "\n",
    "conv_knrm_bigram_model = knrm_train(mus, sigmas, use_conv=use_conv, ngram_size=ngram_size, save_name=CONV_KNRM_BIGRAM_MODEL_NAME, EPOCHS=EPOCHS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rerank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e171f9c49e04694b8015660b7f400f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating_scores_for_reranking:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21bb1cd8e2e247e18b3ff9c176ef08a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=88), Label(value='0 / 88'))), HBox…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: Conv-KNRM Bigram ----\n",
      "MRR@5 on dev set: 0.02830952380952381\n"
     ]
    }
   ],
   "source": [
    "reranked_conv_knrm_bigram_query_dev_df = rerank(df_query_dev, CONV_KNRM_BIGRAM_MODEL_NAME, conv_knrm_bigram_model, DEVICE)\n",
    "reranked_conv_knrm_bigram_query_dev_df.head()\n",
    "\n",
    "# ---- Conv-KNRM with Bigram Re-Ranking ----\n",
    "results_dev = get_performance_mrr(reranked_conv_knrm_bigram_query_dev_df, 'cord_uid', f'{CONV_KNRM_BIGRAM_MODEL_NAME}_topk')\n",
    "print(\"---- Re-Ranking Finetune: Conv-KNRM Bigram ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 5) Evaluation\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5) and compares it to the knrm models discovered in section 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [],
   "source": [
    "# ---- BM25 Baseline ----\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "\n",
    "print(\"---- BM25 Baseline ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")\n",
    "\n",
    "# ---- KNRM Re-Ranking ----\n",
    "results_dev = get_performance_mrr(reranked_knrm_query_dev_df, 'cord_uid', f'{KNRM_MODEL_NAME}_topk')\n",
    "print(\"---- Re-Ranking Finetune: KNRM ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")\n",
    "\n",
    "# ---- Conv-KNRM with 1-gram Re-Ranking ----\n",
    "results_dev = get_performance_mrr(reranked_conv_knrm_query_dev_df, 'cord_uid', f'{CONV_KNRM_MODEL_NAME}_topk')\n",
    "print(\"---- Re-Ranking Finetune: Conv-KNRM 1-gram ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")\n",
    "\n",
    "# ---- Conv-KNRM with Bigram Re-Ranking ----\n",
    "results_dev = get_performance_mrr(reranked_conv_knrm_bigram_query_dev_df, 'cord_uid', f'{CONV_KNRM_BIGRAM_MODEL_NAME}_topk')\n",
    "print(\"---- Re-Ranking Finetune: Conv-KNRM Bigram ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results documentation\n",
    "\n",
    "### 1) KNRM\n",
    "Re-Ranking of top 100 BM25 results for each query:\\\n",
    "MRR@5: 0.025 :(\n",
    "\n",
    "### 2) Conv-KNRM with 1-grams\n",
    "Re-Ranking of top 100 BM25 results for each query:\\\n",
    "MRR@5:\n",
    "\n",
    "### 3) Conv-KNRM with Bigrams\n",
    "Re-Ranking of top 100 BM25 results for each query:\\\n",
    "MRR@5:"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
