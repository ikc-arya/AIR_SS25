{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_def.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_avx2.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_core.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_lp64.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "ERROR: ld.so: object '/opt/conda/lib/libmkl_intel_thread.so' from LD_PRELOAD cannot be preloaded (cannot open shared object file): ignored.\n",
      "Requirement already satisfied: pandarallel in /opt/conda/lib/python3.11/site-packages (1.6.5)\n",
      "Requirement already satisfied: rank_bm25 in /opt/conda/lib/python3.11/site-packages (0.2.2)\n",
      "Requirement already satisfied: dill>=0.3.1 in /opt/conda/lib/python3.11/site-packages (from pandarallel) (0.3.9)\n",
      "Requirement already satisfied: pandas>=1 in /opt/conda/lib/python3.11/site-packages (from pandarallel) (2.2.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from pandarallel) (5.9.8)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from rank_bm25) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1->pandarallel) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1->pandarallel) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.11/site-packages (from pandas>=1->pandarallel) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=1->pandarallel) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandarallel rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM",
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 16 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing query and collection data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "PATH_COLLECTION_DATA = 'subtask_4b/subtask4b_collection_data.pkl' \n",
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "PATH_QUERY_TRAIN_DATA = 'subtask_4b/subtask4b_query_tweets_train.tsv'\n",
    "PATH_QUERY_DEV_DATA = 'subtask_4b/subtask4b_query_tweets_dev.tsv' \n",
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP"
   },
   "source": [
    "# 2) Running the BM25 baseline\n",
    "The following code runs a BM25 baseline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:100] # @k: how many docs shall the ranked list include?\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top100 candidates using the BM25 model\n",
    "\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "if not os.path.exists(train_pkl_path):\n",
    "    df_query_train['bm25_topk'] = df_query_train['tweet_text'].parallel_apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_train.to_pickle(train_pkl_path)\n",
    "else:\n",
    "    df_query_train = pd.read_pickle(train_pkl_path)\n",
    "\n",
    "if not os.path.exists(dev_pkl_path):\n",
    "    df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].parallel_apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_dev.to_pickle(dev_pkl_path)\n",
    "else:\n",
    "    df_query_dev = pd.read_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>normalized_tweet_text</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "      <th>final_query</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>oral care rehabilit medicin oral vulner oral m...</td>\n",
       "      <td>oral care rehabilit medicin oral vulner oral m...</td>\n",
       "      <td>[htlvpvz5, h7hj64q5, trmwm9qq, 65gedo6u, rwgqk...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>studi isnt receiv suffici attent reveal blackl...</td>\n",
       "      <td>studi isnt receiv suffici attent reveal blackl...</td>\n",
       "      <td>[apqzyln2, asdcpvhx, 33znyrn8, ljcdfmbu, 296il...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>thank xi jinp remind studi conclud nonpharmace...</td>\n",
       "      <td>thank xi jinp remind studi conclud nonpharmace...</td>\n",
       "      <td>[jtwb17u8, veeavho5, mwj0xc3q, 8hkxbxz9, a0q61...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "      <td>taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>taiwan popul 23 million 600 case 7 death wides...</td>\n",
       "      <td>taiwan popul 23 million 600 case 7 death wides...</td>\n",
       "      <td>[lsgm7y5t, l5ogbl5p, l4y7v729, x14iywtr, 0w9k8...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "      <td>obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>obtain diagnosi autism lower incom countri tak...</td>\n",
       "      <td>obtain diagnosi autism lower incom countri tak...</td>\n",
       "      <td>[tiqksd69, b0dzhsrh, k7smwz6w, aqbhxv1f, 0u330...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5   \n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul   \n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8   \n",
       "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1   \n",
       "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69   \n",
       "\n",
       "                               normalized_tweet_text  \\\n",
       "0  oral care in rehabilitation medicine: oral vul...   \n",
       "1  this study isn't receiving sufficient attentio...   \n",
       "2  thanks, xi jinping. a reminder that this study...   \n",
       "3  taiwan - a population of 23 million has had ju...   \n",
       "4  obtaining a diagnosis of autism in lower incom...   \n",
       "\n",
       "                                  cleaned_tweet_text  \\\n",
       "0  oral care rehabilit medicin oral vulner oral m...   \n",
       "1  studi isnt receiv suffici attent reveal blackl...   \n",
       "2  thank xi jinp remind studi conclud nonpharmace...   \n",
       "3  taiwan popul 23 million 600 case 7 death wides...   \n",
       "4  obtain diagnosi autism lower incom countri tak...   \n",
       "\n",
       "                                         final_query  \\\n",
       "0  oral care rehabilit medicin oral vulner oral m...   \n",
       "1  studi isnt receiv suffici attent reveal blackl...   \n",
       "2  thank xi jinp remind studi conclud nonpharmace...   \n",
       "3  taiwan popul 23 million 600 case 7 death wides...   \n",
       "4  obtain diagnosi autism lower incom countri tak...   \n",
       "\n",
       "                                           bm25_topk  in_topx  \n",
       "0  [htlvpvz5, h7hj64q5, trmwm9qq, 65gedo6u, rwgqk...      1.0  \n",
       "1  [apqzyln2, asdcpvhx, 33znyrn8, ljcdfmbu, 296il...      0.0  \n",
       "2  [jtwb17u8, veeavho5, mwj0xc3q, 8hkxbxz9, a0q61...      1.0  \n",
       "3  [lsgm7y5t, l5ogbl5p, l4y7v729, x14iywtr, 0w9k8...      0.2  \n",
       "4  [tiqksd69, b0dzhsrh, k7smwz6w, aqbhxv1f, 0u330...      1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the train set: {1: 0.5731735781529604, 5: 0.625250914183459, 10: 0.6308237901348459}\n",
      "Results on the dev set: {1: 0.5657142857142857, 5: 0.616095238095238, 10: 0.6224325396825396}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "\n",
    "# Printed MRR@k results\n",
    "print(f\"Results on the train set: {dict((k, float(v)) for k, v in results_train.items())}\")\n",
    "print(f\"Results on the dev set: {dict((k, float(v)) for k, v in results_dev.items())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>normalized_tweet_text</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "      <th>final_query</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>covid recoveri studi usa reveal proport case e...</td>\n",
       "      <td>covid recoveri studi usa reveal proport case e...</td>\n",
       "      <td>[25aj8rj5, 66g5lpm6, o4vvlmr4, vmmwtdia, trrg1...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>\"among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>among 139 client expos two symptomat hair styl...</td>\n",
       "      <td>among 139 client expos two symptomat hair styl...</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, s2vckt2w, yrowv62k, g5hg3...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>i recall early on reading that researchers wor...</td>\n",
       "      <td>recal earli read research who examin coronavir...</td>\n",
       "      <td>recal earli read research who examin coronavir...</td>\n",
       "      <td>[mkwgkkoi, gruir7aw, xavegbty, vx1hjh26, ntxuf...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>you know you're credible when national institu...</td>\n",
       "      <td>know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...</td>\n",
       "      <td>know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...</td>\n",
       "      <td>[3sr2exq9, sv48gjkk, tx8ypqsm, z795y51f, k0f4c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>resistance to antifungal medications is a grow...</td>\n",
       "      <td>resist antifung medic grow issu global scope d...</td>\n",
       "      <td>resist antifung medic grow issu global scope d...</td>\n",
       "      <td>[ybwwmyqy, ouvq2wpq, rs3umc1x, sxx3yid9, vabb2...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                               normalized_tweet_text  \\\n",
       "0  covid recovery: this study from the usa reveal...   \n",
       "1  \"among 139 clients exposed to two symptomatic ...   \n",
       "2  i recall early on reading that researchers wor...   \n",
       "3  you know you're credible when national institu...   \n",
       "4  resistance to antifungal medications is a grow...   \n",
       "\n",
       "                                  cleaned_tweet_text  \\\n",
       "0  covid recoveri studi usa reveal proport case e...   \n",
       "1  among 139 client expos two symptomat hair styl...   \n",
       "2  recal earli read research who examin coronavir...   \n",
       "3  know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...   \n",
       "4  resist antifung medic grow issu global scope d...   \n",
       "\n",
       "                                         final_query  \\\n",
       "0  covid recoveri studi usa reveal proport case e...   \n",
       "1  among 139 client expos two symptomat hair styl...   \n",
       "2  recal earli read research who examin coronavir...   \n",
       "3  know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...   \n",
       "4  resist antifung medic grow issu global scope d...   \n",
       "\n",
       "                                           bm25_topk  in_topx  \n",
       "0  [25aj8rj5, 66g5lpm6, o4vvlmr4, vmmwtdia, trrg1...      0.0  \n",
       "1  [r58aohnu, p0kg6dyz, s2vckt2w, yrowv62k, g5hg3...      1.0  \n",
       "2  [mkwgkkoi, gruir7aw, xavegbty, vx1hjh26, ntxuf...      0.0  \n",
       "3  [3sr2exq9, sv48gjkk, tx8ypqsm, z795y51f, k0f4c...      1.0  \n",
       "4  [ybwwmyqy, ouvq2wpq, rs3umc1x, sxx3yid9, vabb2...      1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_dev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) BERT Embeddings pre-computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gonna run pytorch on cuda\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return \"cuda\"\n",
    "    elif torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    else:\n",
    "        return \"cpu\"\n",
    "\n",
    "DEVICE = get_device()\n",
    "print(f\"Gonna run pytorch on {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings of a specified text passage from some model\n",
    "def get_token_embeddings(text, tokenizer, model, device):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "# pre compute all the token embeddings of the documents\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    device,\n",
    "    max_len=512,\n",
    "    batch_size=16\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    \n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "    \n",
    "    print(\"Precomputing document embeddings.\")\n",
    "    \n",
    "    texts = []\n",
    "    doc_ids = []\n",
    "    indices = []\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "        texts.append(text)\n",
    "        doc_ids.append(doc_id)\n",
    "        indices.append(i)\n",
    "    \n",
    "    for start_idx in tqdm(range(0, len(texts), batch_size)):\n",
    "        end_idx = min(start_idx + batch_size, len(texts))\n",
    "        batch_texts = texts[start_idx:end_idx]\n",
    "        batch_doc_ids = doc_ids[start_idx:end_idx]\n",
    "        batch_indices = indices[start_idx:end_idx]\n",
    "        \n",
    "        inputs = tokenizer(batch_texts, return_tensors='pt', padding=True, truncation=True, max_length=max_len).to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        q_emb_batch = outputs.last_hidden_state  # [batch_size, L, D]\n",
    "        attention_mask = inputs['attention_mask'].to(torch.bool)\n",
    "        \n",
    "        for i in range(len(batch_texts)):\n",
    "            att_mask = attention_mask[i]\n",
    "            embeddings = q_emb_batch[i][att_mask]\n",
    "            doc_id = batch_doc_ids[i]\n",
    "\n",
    "            file_path = Path(f\"doc_embeddings_{save_dir}\") / f\"{doc_id}.pt\"\n",
    "            torch.save(embeddings, file_path)\n",
    "            n_tokens = embeddings.shape[0]\n",
    "\n",
    "            if doc_id not in metadata:\n",
    "                metadata[doc_id] = {\n",
    "                    \"length\": min(n_tokens, max_len),\n",
    "                    \"path\": str(file_path)\n",
    "                }\n",
    "\n",
    "    metadata_path = Path(f\"doc_embeddings_{save_dir}\") / \"metadata.json\"\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "# either precompute or load precomputed doc embeddings\n",
    "def get_precomputed_doc_embeddings(save_name):\n",
    "    def split_at_slash(s):\n",
    "        if '/' in s:\n",
    "            return s.split('/', 1)\n",
    "        else:\n",
    "            return ['', s]\n",
    "        \n",
    "    if not os.path.exists(\"doc_embeddings_\" + split_at_slash(save_name)[1] + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, \"allenai/scibert_scivocab_uncased\", save_name, DEVICE)\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings_allenai = get_precomputed_doc_embeddings(\"allenai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embeddings_allenai = {\n",
    "    k: {'length': v['length'], 'path': v['path'].replace('all_embeddings', 'allenai')}\n",
    "    for k, v in doc_embeddings_allenai.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4) Neural Re-Ranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create interface for generating convolutional layers for n-grams, calculate the similarity match matrix, generating kernel pooling object and the reranking function itself"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NGram Convolutional Layers class and Similarity Matrix computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NGramConvLayer(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=8, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv1d(in_channels, out_channels, kernel_size, padding=kernel_size//2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: [batch_size, 1, seq_len_q, seq_len_d]\n",
    "        return F.relu(self.conv(x))\n",
    "\n",
    "def compute_similarity_matrix(q_embs, d_embs):\n",
    "    q_norm = F.normalize(q_embs, p=2, dim=1)\n",
    "    d_norm = F.normalize(d_embs, p=2, dim=1)\n",
    "    # cosine similarity matrix\n",
    "    return torch.mm(q_norm, d_norm.T)\n",
    "\n",
    "def process_query_doc(q_embs, d_embs, conv_layer=None):\n",
    "    \"\"\"\n",
    "    q_embs: [L_q, D]\n",
    "    d_embs: [L_d, D]\n",
    "    conv_layer: nn.Module, optional - for modeling n-grams.\n",
    "    \"\"\"\n",
    "    sim_matrix = compute_similarity_matrix(q_embs, d_embs)  # [L_q, L_d]\n",
    "    if conv_layer:\n",
    "        input_tensor = sim_matrix.unsqueeze(0).unsqueeze(0)  # shape: [1,1,L_q,L_d]\n",
    "        conv_output = conv_layer(input_tensor)  # shape: [1,out_channels,L_q,L_d]\n",
    "        pooled = conv_output.max(dim=2)[0].max(dim=2)[0]  # [out_channels]\n",
    "        features = pooled\n",
    "    else:\n",
    "        features = sim_matrix.flatten()\n",
    "    return features\n",
    "\n",
    "def create_ngram_conv_layer(ngram_size):\n",
    "    return NGramConvLayer(in_channels=1, out_channels=8, kernel_size=ngram_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Kernel Pooling Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPooling(nn.Module):\n",
    "    def __init__(self, mus, sigmas):\n",
    "        super().__init__()\n",
    "        self.mus = torch.tensor(mus).view(1, -1)  # shape: [1, num_kernels]\n",
    "        self.sigmas = torch.tensor(sigmas).view(1, -1)\n",
    "\n",
    "    def forward(self, sim_matrix):\n",
    "        # sim_matrix: [L_q, L_d]\n",
    "        sim_matrix = sim_matrix.unsqueeze(0).unsqueeze(0)  # [1,1,L_q,L_d]\n",
    "\n",
    "        mus = self.mus.to(sim_matrix.device)\n",
    "        sigmas = self.sigmas.to(sim_matrix.device)\n",
    "\n",
    "        kernel_vals = torch.exp(- (sim_matrix - mus.reshape(1, -1, 1, 1))**2 / (2 * sigmas.reshape(1, -1, 1, 1)**2))\n",
    "        pooled = kernel_vals.sum(dim=3).sum(dim=2)  # shape: [1, num_kernels]\n",
    "        return pooled.squeeze(0)  # shape: [num_kernels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNRM Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNRM(nn.Module):\n",
    "    def __init__(self, mus, sigmas, conv_layer=None, conv_channels=8):\n",
    "        super().__init__()\n",
    "        self.kernel_pool = KernelPooling(mus, sigmas)\n",
    "        self.conv_layer = conv_layer\n",
    "        n_features = len(mus) * (conv_channels if conv_layer else 1)\n",
    "        self.scorer = nn.Linear(n_features, 1)\n",
    "        \n",
    "    def forward(self, q_emb, d_emb):\n",
    "        q_norm = F.normalize(q_emb, p=2, dim=1)\n",
    "        d_norm = F.normalize(d_emb, p=2, dim=1)\n",
    "        sim_matrix = torch.mm(q_norm, d_norm.T)\n",
    "        pooled_features = self.kernel_pool(sim_matrix)\n",
    "        score = self.scorer(pooled_features)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNRM Triplet Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNRMTripletDataset(Dataset):\n",
    "    def __init__(self, df_query, metadata, tokenizer, num_negatives=1):\n",
    "        self.queries = []\n",
    "        self.pos_ids = []\n",
    "        self.neg_ids = []\n",
    "        \n",
    "        for _, row in df_query.iterrows():\n",
    "            query = row['tweet_text']\n",
    "            pos_id = row['cord_uid']\n",
    "            candidates = row['bm25_topk']\n",
    "            neg_candidates = [doc for doc in candidates if doc != pos_id]\n",
    "            \n",
    "            if neg_candidates:\n",
    "                neg_ids = random.sample(neg_candidates, min(num_negatives, len(neg_candidates)))\n",
    "                for neg_id in neg_ids:\n",
    "                    self.queries.append(query)\n",
    "                    self.pos_ids.append(pos_id)\n",
    "                    self.neg_ids.append(neg_id)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queries)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.queries[idx], self.pos_ids[idx], self.neg_ids[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNRM training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knrm_train(mus, sigmas, save_name, MARGIN=0.5, BATCH_SIZE=8, EPOCHS=6, LR=1e-3):\n",
    "    device = DEVICE\n",
    "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    bert_model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    knrm_model = KNRM(mus, sigmas).to(device)\n",
    "    metadata = get_precomputed_doc_embeddings(model_name)\n",
    "\n",
    "    train_dataset = KNRMTripletDataset(df_query_train, metadata, tokenizer)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(knrm_model.parameters(), lr=LR)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "            \n",
    "            q_embs = []\n",
    "            for query in queries:\n",
    "                q_emb = get_token_embeddings(query, tokenizer, bert_model, device)\n",
    "                q_embs.append(q_emb)\n",
    "            \n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "            \n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(device)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(device)[:metadata[neg_ids[i]][\"length\"]]\n",
    "                \n",
    "                score_pos = knrm_model(q_embs[i], d_pos_emb)\n",
    "                score_neg = knrm_model(q_embs[i], d_neg_emb)\n",
    "                \n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "            \n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "            \n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "    \n",
    "    torch.save(knrm_model.state_dict(), f\"{save_name}.pt\")\n",
    "    return knrm_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precomputing document embeddings.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79442e22600045ceaf00183251f89496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6eb077735e4ff288cc7ca2eedf440d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/483 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a782faeb355e4337b10024c01c2b81eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mus = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "sigmas = [0.1] * len(mus)\n",
    "knrm_model = knrm_train(mus, sigmas, \"knrm\", EPOCHS=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embeddings Caching Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsLoader():\n",
    "    doc_embeddings = {}\n",
    "\n",
    "    @classmethod\n",
    "    def get_embeddings(cls):\n",
    "        if cls.doc_embeddings:\n",
    "            return cls.doc_embeddings\n",
    "        else:\n",
    "            for doc_id, data in tqdm(doc_embeddings_allenai.items(), desc=\"loading_doc_embeddings\"):\n",
    "                emb = torch.load(data[\"path\"], map_location=DEVICE)\n",
    "                cls.doc_embeddings[doc_id] = emb\n",
    "            return cls.doc_embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, save_name, device, mus=None, sigmas=None,\n",
    "           ngram_size=1,  # 1 means no convolution, higher for n-grams\n",
    "           conv_channels=8):  # number of convolution filters\n",
    "    df[f'{save_name}_scores'] = [[]] * len(df)\n",
    "    if mus is None:\n",
    "        mus = [-1.0, -0.5, 0.0, 0.5, 1.0]\n",
    "    if sigmas is None:\n",
    "        sigmas = [0.1] * len(mus)\n",
    "\n",
    "    knrm_model = KNRM(mus, sigmas).to(device)\n",
    "    knrm_model.load_state_dict(torch.load(model_path))\n",
    "    knrm_model.eval()\n",
    "\n",
    "    model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "    kernel_pool = KernelPooling(mus, sigmas).to(device)\n",
    "    conv_layer = None\n",
    "    if ngram_size > 1:\n",
    "        conv_layer = NGramConvLayer(in_channels=1, out_channels=conv_channels, kernel_size=ngram_size).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df), desc='calculating_scores_for_reranking'):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model, device=device)\n",
    "            q_emb = q_emb.to(device)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = EmbeddingsLoader().get_embeddings()[doc]\n",
    "                length = doc_embeddings_allenai[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_emb = d_emb.to(device)\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                if conv_layer:\n",
    "                    features = process_query_doc(q_norm, d_norm, conv_layer)\n",
    "                    score = features.sum().item()\n",
    "                else:\n",
    "                    sim_matrix = torch.mm(q_norm, d_norm.T)\n",
    "                    pooled_features = kernel_pool(sim_matrix)\n",
    "                    score = pooled_features.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, f'{save_name}_scores'] = scores\n",
    "\n",
    "        def sort_docs_by_score(row):\n",
    "            doc_ids = row['bm25_topk']\n",
    "            scores = row[f'{save_name}_scores']\n",
    "            sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "            return sorted_docs\n",
    "\n",
    "        df[f'{save_name}_topk'] = df.parallel_apply(sort_docs_by_score, axis=1)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1) KNRM with plain BERT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "273afeafbc2842dea773c7c10e600471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "calculating_scores_for_reranking:   0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f957597bad341af861755e36a2b159e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=88), Label(value='0 / 88'))), HBoxâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reranked_knrm_query_dev_df = rerank(df_query_dev, 'knrm', DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>normalized_tweet_text</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "      <th>final_query</th>\n",
       "      <th>bm25_topk</th>\n",
       "      <th>in_topx</th>\n",
       "      <th>knrm_scores</th>\n",
       "      <th>knrm_topk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>3qvh482o</td>\n",
       "      <td>covid recovery: this study from the usa reveal...</td>\n",
       "      <td>covid recoveri studi usa reveal proport case e...</td>\n",
       "      <td>covid recoveri studi usa reveal proport case e...</td>\n",
       "      <td>[25aj8rj5, 66g5lpm6, o4vvlmr4, vmmwtdia, trrg1...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[4837.27880859375, 9445.9326171875, 9120.74023...</td>\n",
       "      <td>[hfaiddki, qv31t2vh, mck3rgcm, es8l29ub, xndph...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>69</td>\n",
       "      <td>\"Among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>r58aohnu</td>\n",
       "      <td>\"among 139 clients exposed to two symptomatic ...</td>\n",
       "      <td>among 139 client expos two symptomat hair styl...</td>\n",
       "      <td>among 139 client expos two symptomat hair styl...</td>\n",
       "      <td>[r58aohnu, p0kg6dyz, s2vckt2w, yrowv62k, g5hg3...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[8609.88671875, 8009.35107421875, 8584.9609375...</td>\n",
       "      <td>[4e82s91a, pfvf8ujb, 6hl6rtsh, q5wiqpcb, yjm6a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>73</td>\n",
       "      <td>I recall early on reading that researchers who...</td>\n",
       "      <td>sts48u9i</td>\n",
       "      <td>i recall early on reading that researchers wor...</td>\n",
       "      <td>recal earli read research who examin coronavir...</td>\n",
       "      <td>recal earli read research who examin coronavir...</td>\n",
       "      <td>[mkwgkkoi, gruir7aw, xavegbty, vx1hjh26, ntxuf...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[4086.349853515625, 3776.436767578125, 5343.52...</td>\n",
       "      <td>[nj94rv6f, 9miesbf1, o877uul1, o47v5vgw, vblfe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>93</td>\n",
       "      <td>You know you're credible when NIH website has ...</td>\n",
       "      <td>3sr2exq9</td>\n",
       "      <td>you know you're credible when national institu...</td>\n",
       "      <td>know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...</td>\n",
       "      <td>know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...</td>\n",
       "      <td>[3sr2exq9, sv48gjkk, tx8ypqsm, z795y51f, k0f4c...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[9972.6298828125, 9163.21484375, 7944.3359375,...</td>\n",
       "      <td>[l9u3c1dg, 4jri92pu, mwj0xc3q, pq3n18ae, 0jwed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96</td>\n",
       "      <td>Resistance to antifungal medications is a grow...</td>\n",
       "      <td>ybwwmyqy</td>\n",
       "      <td>resistance to antifungal medications is a grow...</td>\n",
       "      <td>resist antifung medic grow issu global scope d...</td>\n",
       "      <td>resist antifung medic grow issu global scope d...</td>\n",
       "      <td>[ybwwmyqy, ouvq2wpq, rs3umc1x, sxx3yid9, vabb2...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[4706.14599609375, 6618.2578125, 6553.40722656...</td>\n",
       "      <td>[9h74xlvv, 2t1zzigc, 896uzyvv, j1kzjre0, bti9a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0       16  covid recovery: this study from the usa reveal...  3qvh482o   \n",
       "1       69  \"Among 139 clients exposed to two symptomatic ...  r58aohnu   \n",
       "2       73  I recall early on reading that researchers who...  sts48u9i   \n",
       "3       93  You know you're credible when NIH website has ...  3sr2exq9   \n",
       "4       96  Resistance to antifungal medications is a grow...  ybwwmyqy   \n",
       "\n",
       "                               normalized_tweet_text  \\\n",
       "0  covid recovery: this study from the usa reveal...   \n",
       "1  \"among 139 clients exposed to two symptomatic ...   \n",
       "2  i recall early on reading that researchers wor...   \n",
       "3  you know you're credible when national institu...   \n",
       "4  resistance to antifungal medications is a grow...   \n",
       "\n",
       "                                  cleaned_tweet_text  \\\n",
       "0  covid recoveri studi usa reveal proport case e...   \n",
       "1  among 139 client expos two symptomat hair styl...   \n",
       "2  recal earli read research who examin coronavir...   \n",
       "3  know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...   \n",
       "4  resist antifung medic grow issu global scope d...   \n",
       "\n",
       "                                         final_query  \\\n",
       "0  covid recoveri studi usa reveal proport case e...   \n",
       "1  among 139 client expos two symptomat hair styl...   \n",
       "2  recal earli read research who examin coronavir...   \n",
       "3  know your credibl nih websit paper ðŸ’ƒðŸ’ƒ someon p...   \n",
       "4  resist antifung medic grow issu global scope d...   \n",
       "\n",
       "                                           bm25_topk  in_topx  \\\n",
       "0  [25aj8rj5, 66g5lpm6, o4vvlmr4, vmmwtdia, trrg1...      0.0   \n",
       "1  [r58aohnu, p0kg6dyz, s2vckt2w, yrowv62k, g5hg3...      1.0   \n",
       "2  [mkwgkkoi, gruir7aw, xavegbty, vx1hjh26, ntxuf...      0.0   \n",
       "3  [3sr2exq9, sv48gjkk, tx8ypqsm, z795y51f, k0f4c...      1.0   \n",
       "4  [ybwwmyqy, ouvq2wpq, rs3umc1x, sxx3yid9, vabb2...      1.0   \n",
       "\n",
       "                                         knrm_scores  \\\n",
       "0  [4837.27880859375, 9445.9326171875, 9120.74023...   \n",
       "1  [8609.88671875, 8009.35107421875, 8584.9609375...   \n",
       "2  [4086.349853515625, 3776.436767578125, 5343.52...   \n",
       "3  [9972.6298828125, 9163.21484375, 7944.3359375,...   \n",
       "4  [4706.14599609375, 6618.2578125, 6553.40722656...   \n",
       "\n",
       "                                           knrm_topk  \n",
       "0  [hfaiddki, qv31t2vh, mck3rgcm, es8l29ub, xndph...  \n",
       "1  [4e82s91a, pfvf8ujb, 6hl6rtsh, q5wiqpcb, yjm6a...  \n",
       "2  [nj94rv6f, 9miesbf1, o877uul1, o47v5vgw, vblfe...  \n",
       "3  [l9u3c1dg, 4jri92pu, mwj0xc3q, pq3n18ae, 0jwed...  \n",
       "4  [9h74xlvv, 2t1zzigc, 896uzyvv, j1kzjre0, bti9a...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reranked_knrm_query_dev_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 5) Evaluation\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- BM25 Baseline ----\n",
      "Results on the train set: {1: 0.5731735781529604, 5: 0.625250914183459, 10: 0.6308237901348459}\n",
      "Results on the dev set: {1: 0.5657142857142857, 5: 0.616095238095238, 10: 0.6224325396825396}\n"
     ]
    }
   ],
   "source": [
    "# ---- BM25 Baseline ----\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "\n",
    "print(\"---- BM25 Baseline ----\")\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Re-Ranking Finetune: KNRM ----\n",
      "MRR@5 on dev set: 0.024595238095238097\n"
     ]
    }
   ],
   "source": [
    "# ---- KNRM Re-Ranking ----\n",
    "model_name = \"knrm\"\n",
    "\n",
    "results_dev = get_performance_mrr(reranked_knrm_query_dev_df, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Re-Ranking Finetune: KNRM ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results documentation\n",
    "\n",
    "### 1) KNRM\n",
    "Re-Ranking of top 100 BM25 results for each query:\\\n",
    "MRR@5: 0.025 :(\n",
    "\n",
    "### 2) Conv-KNRM with 1-Grams\n",
    "Re-Ranking of top 100 BM25 results for each query:\\\n",
    "MRR@5: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 6) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "model_name = \"bm25\"\n",
    "\n",
    "df_query_dev['preds'] = df_query_dev[f'{model_name}_topk'].parallel_apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
