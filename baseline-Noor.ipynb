{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MfnQvGfvtH1w"
   },
   "source": [
    "# Getting started\n",
    "\n",
    "### CLEF 2025 - CheckThat! Lab  - Task 4 Scientific Web Discourse - Subtask 4b (Scientific Claim Source Retrieval)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **https://www.nltk.org/**\n",
    "- **https://spacy.io/docs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.9.1)\n",
      "Requirement already satisfied: spacy in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.5)\n",
      "Requirement already satisfied: click in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (1.4.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (2024.4.16)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk) (4.66.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm->nltk) (0.4.6)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install nltk spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.8.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (8.3.6)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (0.15.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (4.66.6)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.2.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (2.11.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.1.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (69.5.1)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (24.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from spacy) (3.5.0)\n",
      "Requirement already satisfied: language-data>=1.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.3.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.33.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.13.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy) (2023.7.22)\n",
      "Requirement already satisfied: blis<1.4.0,>=1.3.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.0)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy) (0.4.6)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy) (14.0.0)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.21.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=1.1.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.17.2)\n",
      "Requirement already satisfied: wrapt in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.14.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "     ---------------------------------------- 0.0/12.8 MB ? eta -:--:--\n",
      "     --------------------------------------- 0.0/12.8 MB 640.0 kB/s eta 0:00:20\n",
      "     --------------------------------------- 0.0/12.8 MB 325.1 kB/s eta 0:00:40\n",
      "     --------------------------------------- 0.1/12.8 MB 525.1 kB/s eta 0:00:25\n",
      "     --------------------------------------- 0.1/12.8 MB 853.3 kB/s eta 0:00:15\n",
      "      --------------------------------------- 0.3/12.8 MB 1.2 MB/s eta 0:00:11\n",
      "     - -------------------------------------- 0.4/12.8 MB 1.4 MB/s eta 0:00:09\n",
      "     - -------------------------------------- 0.6/12.8 MB 2.0 MB/s eta 0:00:06\n",
      "     -- ------------------------------------- 0.8/12.8 MB 2.2 MB/s eta 0:00:06\n",
      "     --- ------------------------------------ 1.0/12.8 MB 2.5 MB/s eta 0:00:05\n",
      "     --- ------------------------------------ 1.2/12.8 MB 2.8 MB/s eta 0:00:05\n",
      "     ---- ----------------------------------- 1.4/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     ---- ----------------------------------- 1.5/12.8 MB 2.9 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.8/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ----- ---------------------------------- 1.9/12.8 MB 3.1 MB/s eta 0:00:04\n",
      "     ------ --------------------------------- 2.1/12.8 MB 3.2 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.4/12.8 MB 3.4 MB/s eta 0:00:04\n",
      "     ------- -------------------------------- 2.5/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.7/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     -------- ------------------------------- 2.8/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 2.9/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     --------- ------------------------------ 3.0/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.3/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ---------- ----------------------------- 3.5/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.7/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     ----------- ---------------------------- 3.8/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 3.9/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------ --------------------------- 4.1/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.2/12.8 MB 3.5 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.3/12.8 MB 3.4 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.4/12.8 MB 3.3 MB/s eta 0:00:03\n",
      "     ------------- -------------------------- 4.5/12.8 MB 3.2 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.5/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.6/12.8 MB 3.1 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.7/12.8 MB 3.0 MB/s eta 0:00:03\n",
      "     -------------- ------------------------- 4.7/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.8/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.9/12.8 MB 2.9 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 4.9/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.0/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     --------------- ------------------------ 5.1/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.2/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.3/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ---------------- ----------------------- 5.4/12.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.8/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 5.9/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------ --------------------- 6.0/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     ------------------- -------------------- 6.2/12.8 MB 2.6 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.5/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "     -------------------- ------------------- 6.7/12.8 MB 2.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 7.0/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.1/12.8 MB 2.8 MB/s eta 0:00:03\n",
      "     ---------------------- ----------------- 7.3/12.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ----------------------- ---------------- 7.5/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.7/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------------ --------------- 7.9/12.8 MB 2.9 MB/s eta 0:00:02\n",
      "     ------------------------- -------------- 8.2/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     -------------------------- ------------- 8.4/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.7/12.8 MB 3.0 MB/s eta 0:00:02\n",
      "     --------------------------- ------------ 8.9/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 9.1/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.3/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     ----------------------------- ---------- 9.5/12.8 MB 3.1 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 9.8/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 10.1/12.8 MB 3.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 10.3/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.6/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     --------------------------------- ------ 10.8/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ----- 11.0/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.3/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 11.5/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 11.6/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 11.8/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ------------------------------------- -- 12.1/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- - 12.3/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.6/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.7/12.8 MB 3.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------  12.8/12.8 MB 3.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 12.8/12.8 MB 3.4 MB/s eta 0:00:00\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install spacy\n",
    "!python -m spacy download en_core_web_sm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u8N7h9BhQI5m"
   },
   "source": [
    "## 1.a) Import the collection set\n",
    "The collection set contains metadata of CORD-19 academic papers.\n",
    "\n",
    "The preprocessed and filtered CORD-19 dataset is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1742975971100,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "2GQI4HcKR6hS"
   },
   "outputs": [],
   "source": [
    "# 1) Download the collection set from the Gitlab repository: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "# 2) Drag and drop the downloaded file to the \"Files\" section (left vertical menu on Colab)\n",
    "# 3) Modify the path to your local file path\n",
    "PATH_COLLECTION_DATA = 'subtask_4b/subtask4b_collection_data.pkl' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1742975975524,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "SYBB3UYbMwTA"
   },
   "outputs": [],
   "source": [
    "df_collection = pd.read_pickle(PATH_COLLECTION_DATA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframe Information (`df_collection.info()`):\n",
    "\n",
    "The dataframe `df_collection` contains **7,718 entries** (rows) and **17 columns**. This is the metadata for **7,718 papers** in the CORD-19 dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1742975976305,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "4v3lygNOQQSn",
    "outputId": "ee5b9abd-f889-4a4e-ce11-32d2691433cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 7718 entries, 162 to 1056448\n",
      "Data columns (total 17 columns):\n",
      " #   Column            Non-Null Count  Dtype         \n",
      "---  ------            --------------  -----         \n",
      " 0   cord_uid          7718 non-null   object        \n",
      " 1   source_x          7718 non-null   object        \n",
      " 2   title             7718 non-null   object        \n",
      " 3   doi               7677 non-null   object        \n",
      " 4   pmcid             4959 non-null   object        \n",
      " 5   pubmed_id         6233 non-null   object        \n",
      " 6   license           7718 non-null   object        \n",
      " 7   abstract          7718 non-null   object        \n",
      " 8   publish_time      7715 non-null   object        \n",
      " 9   authors           7674 non-null   object        \n",
      " 10  journal           6668 non-null   object        \n",
      " 11  mag_id            0 non-null      float64       \n",
      " 12  who_covidence_id  528 non-null    object        \n",
      " 13  arxiv_id          20 non-null     object        \n",
      " 14  label             7718 non-null   object        \n",
      " 15  time              7715 non-null   datetime64[ns]\n",
      " 16  timet             7718 non-null   int64         \n",
      "dtypes: datetime64[ns](1), float64(1), int64(1), object(14)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_collection.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Columns in the Dataset:\n",
    "The columns in the dataframe are:\n",
    "\n",
    "- **cord_uid**: A unique identifier for each paper in the CORD-19 collection.\n",
    "- **source_x**: The source from which the paper is retrieved.\n",
    "- **title**: The title of the paper.\n",
    "- **doi**: The digital object identifier (DOI) of the paper.\n",
    "- **pmcid**: PubMed Central ID. \n",
    "- **pubmed_id**: PubMed ID.\n",
    "- **license**: The license type of the paper.\n",
    "- **publish_time**: The publication date of the paper.\n",
    "- **abstract**: A brief summary of the paper.\n",
    "- **authors**: The authors of the paper.\n",
    "- **journal**: The journal in which the paper was published.\n",
    "- **mag_id**: Metadata related to the publication.\n",
    "- **who_covidence_id**: WHO-Covidence identifier.\n",
    "- **arxiv_id**: The identifier for papers available on arXiv.\n",
    "- **label**: A label related to the paper (such as category or relevance).\n",
    "- **timed**: Time-related data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "executionInfo": {
     "elapsed": 211,
     "status": "ok",
     "timestamp": 1742975978238,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "9veNFFGDZRx7",
    "outputId": "5eec7f85-7d20-44d7-8986-a85cb00533d8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>source_x</th>\n",
       "      <th>title</th>\n",
       "      <th>doi</th>\n",
       "      <th>pmcid</th>\n",
       "      <th>pubmed_id</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>publish_time</th>\n",
       "      <th>authors</th>\n",
       "      <th>journal</th>\n",
       "      <th>mag_id</th>\n",
       "      <th>who_covidence_id</th>\n",
       "      <th>arxiv_id</th>\n",
       "      <th>label</th>\n",
       "      <th>time</th>\n",
       "      <th>timet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>10.1371/journal.pone.0002618</td>\n",
       "      <td>PMC2440799</td>\n",
       "      <td>18612429</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>van der Sande, Marianne; Teunis, Peter; Sabel,...</td>\n",
       "      <td>PLoS One</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>umvrwgaw</td>\n",
       "      <td>2008-07-09</td>\n",
       "      <td>1215561600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>PMC</td>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>10.1155/2011/527610</td>\n",
       "      <td>PMC3157160</td>\n",
       "      <td>21860658</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>Li, Jing; Blakeley, Daniel; Smith?, Robert J.</td>\n",
       "      <td>Comput Math Methods Med</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>spiud6ok</td>\n",
       "      <td>2011-08-16</td>\n",
       "      <td>1313452800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>10.4103/0970-2113.99118</td>\n",
       "      <td>PMC3424870</td>\n",
       "      <td>22919170</td>\n",
       "      <td>cc-by-nc-sa</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>2012</td>\n",
       "      <td>Singh, Virendra; Sharma, Bharat Bhushan; Patel...</td>\n",
       "      <td>Lung India</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>aclzp3iy</td>\n",
       "      <td>2012-01-01</td>\n",
       "      <td>1325376000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>PMC</td>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>10.3389/fcimb.2012.00150</td>\n",
       "      <td>PMC3509329</td>\n",
       "      <td>23226686</td>\n",
       "      <td>cc-by</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>Milton, Donald K.</td>\n",
       "      <td>Front Cell Infect Microbiol</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ycxyn2a2</td>\n",
       "      <td>2012-11-29</td>\n",
       "      <td>1354147200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>PMC</td>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>10.3201/eid1902.120312</td>\n",
       "      <td>PMC3559034</td>\n",
       "      <td>23343512</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>Tognotti, Eugenia</td>\n",
       "      <td>Emerg Infect Dis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>zxe95qy9</td>\n",
       "      <td>2013-02-03</td>\n",
       "      <td>1359849600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      cord_uid source_x                                              title  \\\n",
       "162   umvrwgaw      PMC  Professional and Home-Made Face Masks Reduce E...   \n",
       "611   spiud6ok      PMC                               The Failure of R (0)   \n",
       "918   aclzp3iy      PMC  Pulmonary sequelae in a patient recovered from...   \n",
       "993   ycxyn2a2      PMC  What was the primary mode of smallpox transmis...   \n",
       "1053  zxe95qy9      PMC  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                               doi       pmcid pubmed_id      license  \\\n",
       "162   10.1371/journal.pone.0002618  PMC2440799  18612429        cc-by   \n",
       "611            10.1155/2011/527610  PMC3157160  21860658        cc-by   \n",
       "918        10.4103/0970-2113.99118  PMC3424870  22919170  cc-by-nc-sa   \n",
       "993       10.3389/fcimb.2012.00150  PMC3509329  23226686        cc-by   \n",
       "1053        10.3201/eid1902.120312  PMC3559034  23343512        no-cc   \n",
       "\n",
       "                                               abstract publish_time  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   2008-07-09   \n",
       "611   The basic reproductive ratio, R (0), is one of...   2011-08-16   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...         2012   \n",
       "993   The mode of infection transmission has profoun...   2012-11-29   \n",
       "1053  In the new millennium, the centuries-old strat...   2013-02-03   \n",
       "\n",
       "                                                authors  \\\n",
       "162   van der Sande, Marianne; Teunis, Peter; Sabel,...   \n",
       "611       Li, Jing; Blakeley, Daniel; Smith?, Robert J.   \n",
       "918   Singh, Virendra; Sharma, Bharat Bhushan; Patel...   \n",
       "993                                   Milton, Donald K.   \n",
       "1053                                  Tognotti, Eugenia   \n",
       "\n",
       "                          journal  mag_id who_covidence_id arxiv_id     label  \\\n",
       "162                      PLoS One     NaN              NaN      NaN  umvrwgaw   \n",
       "611       Comput Math Methods Med     NaN              NaN      NaN  spiud6ok   \n",
       "918                    Lung India     NaN              NaN      NaN  aclzp3iy   \n",
       "993   Front Cell Infect Microbiol     NaN              NaN      NaN  ycxyn2a2   \n",
       "1053             Emerg Infect Dis     NaN              NaN      NaN  zxe95qy9   \n",
       "\n",
       "           time       timet  \n",
       "162  2008-07-09  1215561600  \n",
       "611  2011-08-16  1313452800  \n",
       "918  2012-01-01  1325376000  \n",
       "993  2012-11-29  1354147200  \n",
       "1053 2013-02-03  1359849600  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this process, I performed several text preprocessing steps on the **title** and **abstract** columns of the dataset **df_collection** First, I removed any URLs using a regular expression. I then removed punctuation and digits, converted the text to lowercase, and eliminated common stopwords, except for those found in the **important_terms** list, which includes relevant medical terms like disease names and pathogens. To further lemmatization the text, I applied stemming to all words, except for those in the **important_terms** list. Additionally, I used the **spaCy** library to extract named entities from both the **title** and **abstract** columns. I also cleaned up extra spaces by reducing multiple spaces to a single one . As a result of these preprocessing steps, I created new columns for the cleaned **title** and **abstract**, as well as for the extracted entities from both columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  title  \\\n",
      "162   Professional and Home-Made Face Masks Reduce E...   \n",
      "611                                The Failure of R (0)   \n",
      "918   Pulmonary sequelae in a patient recovered from...   \n",
      "993   What was the primary mode of smallpox transmis...   \n",
      "1053  Lessons from the History of Quarantine, from P...   \n",
      "\n",
      "                                          cleaned_title  \\\n",
      "162   profession homemad face mask reduc exposur res...   \n",
      "611                                            failur r   \n",
      "918           pulmonari sequela patient recov swine flu   \n",
      "993    primari mode smallpox transmiss implic biodefens   \n",
      "1053           lesson histori quarantin plagu influenza   \n",
      "\n",
      "                                               abstract  \\\n",
      "162   BACKGROUND: Governments are preparing for a po...   \n",
      "611   The basic reproductive ratio, R (0), is one of...   \n",
      "918   The pandemic of swine flu (H1N1) influenza spr...   \n",
      "993   The mode of infection transmission has profoun...   \n",
      "1053  In the new millennium, the centuries-old strat...   \n",
      "\n",
      "                                       cleaned_abstract  \\\n",
      "162   background govern prepar potenti influenza pan...   \n",
      "611   basic reproduct ratio r one fundament concept ...   \n",
      "918   pandemic swine flu hn influenza spread involv ...   \n",
      "993   mode infect transmiss profound implic effect c...   \n",
      "1053  new millennium centuriesold strategi quarantin...   \n",
      "\n",
      "                     entities_in_title  \\\n",
      "162                                 []   \n",
      "611                                 []   \n",
      "918                [pulmonari sequela]   \n",
      "993   [primari mode, transmiss implic]   \n",
      "1053        [lesson histori quarantin]   \n",
      "\n",
      "                                   entities_in_abstract  \n",
      "162   [gener, potenti provid person respir, varieti ...  \n",
      "611   [one, wholli suscept popul, indic, measur, dis...  \n",
      "918   [rapidli mani, scan, diffus capac note, month ...  \n",
      "993   [mode transmiss, second, mucos, measur, mediat...  \n",
      "1053  [new millennium centuriesold, emerg reemerg, i...  \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import spacy\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "\n",
    "important_terms = {\n",
    "    'covid', 'covid-19', 'hiv', 'rna', 'sars', 'r0', 'h1n1', 'who', 'cdc', \n",
    "    'micro', 'kg', 'm/s', 'flu', 'cancer', 'aids', 'diabetes', 'malaria', \n",
    "    'tuberculosis', 'hepatitis', 'pneumonia', 'leprosy', 'arthritis', 'asthma', \n",
    "    'hypertension', 'obesity', 'influenza', 'hiv', 'hepatitis-b', 'coronavirus', \n",
    "    'outbreak', 'pandemic', 'endemic', 'vaccine', 'antiviral', 'antibiotic', \n",
    "    'surgical', 'gene', 'genome', 'mutation', 'pathogen'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    \n",
    "  \n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    \n",
    "   #remove all digits \n",
    "    text = ' '.join([word if word in important_terms else re.sub(r'\\d+', '', word) for word in text.split()])\n",
    "\n",
    "    \n",
    " \n",
    "    text = text.lower()\n",
    "    \n",
    "    text = ' '.join([word for word in text.split() if word not in stop_words or word in important_terms])\n",
    "    \n",
    "    text = ' '.join([stemmer.stem(word) if word not in important_terms else word for word in text.split()])\n",
    "    \n",
    "  \n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents] \n",
    "    \n",
    "    #remove multiple spaces \n",
    "\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text, entities\n",
    "\n",
    "\n",
    "df_collection['cleaned_title'], df_collection['entities_in_title'] = zip(*df_collection['title'].apply(preprocess_text))\n",
    "df_collection['cleaned_abstract'], df_collection['entities_in_abstract'] = zip(*df_collection['abstract'].apply(preprocess_text))\n",
    "\n",
    "# Show some results to verify\n",
    "print(df_collection[['title', 'cleaned_title', 'abstract', 'cleaned_abstract', 'entities_in_title', 'entities_in_abstract']].head())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cleaned_title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>cleaned_abstract</th>\n",
       "      <th>entities_in_title</th>\n",
       "      <th>entities_in_abstract</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Professional and Home-Made Face Masks Reduce E...</td>\n",
       "      <td>profession homemad face mask reduc exposur res...</td>\n",
       "      <td>BACKGROUND: Governments are preparing for a po...</td>\n",
       "      <td>background govern prepar potenti influenza pan...</td>\n",
       "      <td>[Professional and Home-Made Face Masks Reduce ...</td>\n",
       "      <td>[PRINCIPAL, Outward]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>The Failure of R (0)</td>\n",
       "      <td>failur r</td>\n",
       "      <td>The basic reproductive ratio, R (0), is one of...</td>\n",
       "      <td>basic reproduct ratio r one fundament concept ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[1, 1, 1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Pulmonary sequelae in a patient recovered from...</td>\n",
       "      <td>pulmonari sequela patient recov swine flu</td>\n",
       "      <td>The pandemic of swine flu (H1N1) influenza spr...</td>\n",
       "      <td>pandemic swine flu hn influenza spread involv ...</td>\n",
       "      <td>[Pulmonary]</td>\n",
       "      <td>[3 months]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>What was the primary mode of smallpox transmis...</td>\n",
       "      <td>primari mode smallpox transmiss implic biodefens</td>\n",
       "      <td>The mode of infection transmission has profoun...</td>\n",
       "      <td>mode infect transmiss profound implic effect c...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[a few seconds, the last decades, Variola]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Lessons from the History of Quarantine, from P...</td>\n",
       "      <td>lesson histori quarantin plagu influenza</td>\n",
       "      <td>In the new millennium, the centuries-old strat...</td>\n",
       "      <td>new millennium centuriesold strategi quarantin...</td>\n",
       "      <td>[the History of Quarantine, Plague]</td>\n",
       "      <td>[the new millennium, centuries-old, 2003, just...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title  \\\n",
       "162   Professional and Home-Made Face Masks Reduce E...   \n",
       "611                                The Failure of R (0)   \n",
       "918   Pulmonary sequelae in a patient recovered from...   \n",
       "993   What was the primary mode of smallpox transmis...   \n",
       "1053  Lessons from the History of Quarantine, from P...   \n",
       "\n",
       "                                          cleaned_title  \\\n",
       "162   profession homemad face mask reduc exposur res...   \n",
       "611                                            failur r   \n",
       "918           pulmonari sequela patient recov swine flu   \n",
       "993    primari mode smallpox transmiss implic biodefens   \n",
       "1053           lesson histori quarantin plagu influenza   \n",
       "\n",
       "                                               abstract  \\\n",
       "162   BACKGROUND: Governments are preparing for a po...   \n",
       "611   The basic reproductive ratio, R (0), is one of...   \n",
       "918   The pandemic of swine flu (H1N1) influenza spr...   \n",
       "993   The mode of infection transmission has profoun...   \n",
       "1053  In the new millennium, the centuries-old strat...   \n",
       "\n",
       "                                       cleaned_abstract  \\\n",
       "162   background govern prepar potenti influenza pan...   \n",
       "611   basic reproduct ratio r one fundament concept ...   \n",
       "918   pandemic swine flu hn influenza spread involv ...   \n",
       "993   mode infect transmiss profound implic effect c...   \n",
       "1053  new millennium centuriesold strategi quarantin...   \n",
       "\n",
       "                                      entities_in_title  \\\n",
       "162   [Professional and Home-Made Face Masks Reduce ...   \n",
       "611                                                  []   \n",
       "918                                         [Pulmonary]   \n",
       "993                                                  []   \n",
       "1053                [the History of Quarantine, Plague]   \n",
       "\n",
       "                                   entities_in_abstract  \n",
       "162                                [PRINCIPAL, Outward]  \n",
       "611                                     [1, 1, 1, 1, 1]  \n",
       "918                                          [3 months]  \n",
       "993          [a few seconds, the last decades, Variola]  \n",
       "1053  [the new millennium, centuries-old, 2003, just...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection[['title', 'cleaned_title', 'abstract', 'cleaned_abstract', 'entities_in_title', 'entities_in_abstract']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the code, I created a function `extract_entities` that uses the `spaCy` library to perform Named Entity Recognition (NER) on the input text. The function processes the text and extracts the recognized entities as a list. I then applied this function to the `title` and `abstract` columns of the `df_collection` dataset, storing the extracted entities in two new columns: `entities_in_title` and `entities_in_abstract`. These columns now contain lists of entities that were identified in the  `title` and `abstract` of each record.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(text):\n",
    "    doc = nlp(text)\n",
    "    entities = [ent.text for ent in doc.ents]\n",
    "    return entities\n",
    "\n",
    "df_collection['entities_in_title'] = df_collection['title'].apply(extract_entities)\n",
    "df_collection['entities_in_abstract'] = df_collection['abstract'].apply(extract_entities)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['cord_uid', 'source_x', 'title', 'doi', 'pmcid', 'pubmed_id', 'license',\n",
       "       'abstract', 'publish_time', 'authors', 'journal', 'mag_id',\n",
       "       'who_covidence_id', 'arxiv_id', 'label', 'time', 'timet',\n",
       "       'cleaned_title', 'entities_in_title', 'cleaned_abstract',\n",
       "       'entities_in_abstract'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_collection.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "filtered_df = df_collection[['title', 'abstract', 'cleaned_title', 'cleaned_abstract', 'entities_in_title', 'entities_in_abstract']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AAUiDU0xXLBt"
   },
   "source": [
    "## 1.b) Import the query set\n",
    "\n",
    "The query set contains tweets with implicit references to academic papers from the collection set.\n",
    "\n",
    "The preprocessed query set is available on the Gitlab repository here: https://gitlab.com/checkthat_lab/clef2025-checkthat-lab/-/tree/main/task4/subtask_4b\n",
    "\n",
    "Participants should first download the file then upload it on the Google Colab session with the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1742975982410,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "v8gwkZDSXPsd"
   },
   "outputs": [],
   "source": [
    "\n",
    "PATH_QUERY_TRAIN_DATA = 'subtask_4b/subtask4b_query_tweets_train.tsv' \n",
    "PATH_QUERY_DEV_DATA = 'subtask_4b/subtask4b_query_tweets_dev.tsv' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1742976006985,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "VqxjYq2tYDmE"
   },
   "outputs": [],
   "source": [
    "df_query_train = pd.read_csv(PATH_QUERY_TRAIN_DATA, sep = '\\t')\n",
    "df_query_dev = pd.read_csv(PATH_QUERY_DEV_DATA, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tweettext** column was cleaned using the **preprocess_text** function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_query_train['cleaned_tweet_text'] = df_query_train['tweet_text'].apply(preprocess_text)\n",
    "df_query_train['cleaned_tweet_text'] = df_query_train['cleaned_tweet_text'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "df_query_dev['cleaned_tweet_text'] = df_query_dev['tweet_text'].apply(preprocess_text)\n",
    "df_query_dev['cleaned_tweet_text'] = df_query_dev['cleaned_tweet_text'].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['post_id', 'tweet_text', 'cord_uid', 'cleaned_tweet_text']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df_query_dev.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>tweet_text</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>cleaned_tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Oral care in rehabilitation medicine: oral vul...</td>\n",
       "      <td>htlvpvz5</td>\n",
       "      <td>('oral care rehabilit medicin oral vulner oral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>this study isn't receiving sufficient attentio...</td>\n",
       "      <td>4kfl29ul</td>\n",
       "      <td>('studi isnt receiv suffici attent reveal blac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>thanks, xi jinping. a reminder that this study...</td>\n",
       "      <td>jtwb17u8</td>\n",
       "      <td>('thank xi jinp remind studi conclud nonpharma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Taiwan - a population of 23 million has had ju...</td>\n",
       "      <td>0w9k8iy1</td>\n",
       "      <td>('taiwan popul million case amp death widespre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Obtaining a diagnosis of autism in lower incom...</td>\n",
       "      <td>tiqksd69</td>\n",
       "      <td>('obtain diagnosi autism lower incom countri t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   post_id                                         tweet_text  cord_uid  \\\n",
       "0        0  Oral care in rehabilitation medicine: oral vul...  htlvpvz5   \n",
       "1        1  this study isn't receiving sufficient attentio...  4kfl29ul   \n",
       "2        2  thanks, xi jinping. a reminder that this study...  jtwb17u8   \n",
       "3        3  Taiwan - a population of 23 million has had ju...  0w9k8iy1   \n",
       "4        4  Obtaining a diagnosis of autism in lower incom...  tiqksd69   \n",
       "\n",
       "                                  cleaned_tweet_text  \n",
       "0  ('oral care rehabilit medicin oral vulner oral...  \n",
       "1  ('studi isnt receiv suffici attent reveal blac...  \n",
       "2  ('thank xi jinp remind studi conclud nonpharma...  \n",
       "3  ('taiwan popul million case amp death widespre...  \n",
       "4  ('obtain diagnosi autism lower incom countri t...  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_query_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply the **extract_entities** function to the **tweet_text** column and store the resulting entities in a single column for both the training and development datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_query_train['entities_in_tweet_text_train'] = df_query_train['tweet_text'].apply(extract_entities)\n",
    "df_query_train['entities_in_tweet_text_train'] = df_query_train['entities_in_tweet_text_train'].fillna('').astype(str)\n",
    "\n",
    "\n",
    "df_query_dev['entities_in_tweet_text_dev'] = df_query_dev['tweet_text'].apply(extract_entities)\n",
    "df_query_dev['entities_in_tweet_text_dev'] = df_query_dev['entities_in_tweet_text_dev'].fillna('').astype(str)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jr_BDzufPmmP"
   },
   "source": [
    "# 2)The following code runs a BM25 after preprcoessing \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rank_bm25 in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp-zbook i7\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rank_bm25) (2.2.4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install rank_bm25\n",
    "from rank_bm25 import BM25Okapi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "\n",
    "corpus = df_collection[['cleaned_title', 'cleaned_abstract', 'entities_in_title', 'entities_in_abstract']].apply(\n",
    "    lambda x: f\"{x['cleaned_title']} {x['cleaned_abstract']} {' '.join(x['entities_in_title'])} {' '.join(x['entities_in_abstract'])}\",\n",
    "    axis=1\n",
    ").tolist()\n",
    "\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "\n",
    "\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "    \n",
    "\n",
    "      #based on the tokenized query we call the BM25 to compute the relevance score for each document relevant to the query \n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      # it sort the doc scores in descending order \n",
    "      indices = np.argsort(-doc_scores)[:5]\n",
    "      #This line uses the indices from the previous step to retrieve the actual document IDs \n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "      \n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_query_train['final_query'] = df_query_train['cleaned_tweet_text'] + ' ' + df_query_train['entities_in_tweet_text_train']\n",
    "df_query_dev['final_query'] = df_query_dev['cleaned_tweet_text'] + ' ' + df_query_dev['entities_in_tweet_text_dev']\n",
    "\n",
    "\n",
    "df_query_train['bm25_topk'] = df_query_train['final_query'].apply(lambda x: get_top_cord_uids(x))\n",
    "df_query_dev['bm25_topk'] = df_query_dev['final_query'].apply(lambda x: get_top_cord_uids(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 3) Evaluating the baseline\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1742976568622,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "xLX9SMg5USkH",
    "outputId": "7c414679-6486-4e08-dffe-23d8cffbddf0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results on the train set: {1: np.float64(0.5221349101377111), 5: np.float64(0.5746868435384734), 10: np.float64(0.5746868435384734)}\n",
      "Results on the dev set: {1: np.float64(0.5185714285714286), 5: np.float64(0.5740119047619048), 10: np.float64(0.5740119047619048)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "results_train = get_performance_mrr(df_query_train, 'cord_uid', 'bm25_topk')\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', 'bm25_topk')\n",
    "\n",
    "# Printed MRR@k results\n",
    "print(f\"Results on the train set: {results_train}\")\n",
    "print(f\"Results on the dev set: {results_dev}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 4) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "df_query_dev['preds'] = df_query_dev['bm25_topk'].apply(lambda x: x[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_dev[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
