{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 403,
     "status": "ok",
     "timestamp": 1742975967136,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "rQPqDKP_QHFM"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.functional import cosine_similarity\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "from pathlib import Path\n",
    "import re\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vpDCfBMouNAL"
   },
   "source": [
    "# 1) Importing BM25 preranked docs for each query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load BM25 pre-ranked query dataframes\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "test_pkl_path = 'df_query_test_top100.pkl'\n",
    "\n",
    "df_query_dev = pd.read_pickle(dev_pkl_path)\n",
    "df_query_train = pd.read_pickle(train_pkl_path)\n",
    "df_query_test = pd.read_pickle(test_pkl_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3156,
     "status": "ok",
     "timestamp": 1742976045832,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "BHfJ7ItxO8u8",
    "outputId": "8a4d8f08-31c0-4a9d-814e-b921b80fbe35"
   },
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 1414,
     "status": "ok",
     "timestamp": 1742976047296,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "jXCC7K_ZPQL2"
   },
   "outputs": [],
   "source": [
    "# Create the BM25 corpus\n",
    "corpus = df_collection[:][['title', 'abstract']].apply(lambda x: f\"{x['title']} {x['abstract']}\", axis=1).tolist()\n",
    "cord_uids = df_collection[:]['cord_uid'].tolist()\n",
    "tokenized_corpus = [doc.split(' ') for doc in corpus]\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1742976047304,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "e8NeJWGYPQZG"
   },
   "outputs": [],
   "source": [
    "def get_top_cord_uids(query):\n",
    "  text2bm25top = {}\n",
    "  if query in text2bm25top.keys():\n",
    "      return text2bm25top[query]\n",
    "  else:\n",
    "      tokenized_query = query.split(' ')\n",
    "      doc_scores = bm25.get_scores(tokenized_query)\n",
    "      indices = np.argsort(-doc_scores)[:100] # @k: how many docs shall the ranked list include?\n",
    "      bm25_topk = [cord_uids[x] for x in indices]\n",
    "\n",
    "      text2bm25top[query] = bm25_topk\n",
    "      return bm25_topk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve top50 candidates using the BM25 model\n",
    "\n",
    "train_pkl_path = 'df_query_train_top100.pkl'\n",
    "dev_pkl_path = 'df_query_dev_top100.pkl'\n",
    "\n",
    "if not os.path.exists(train_pkl_path):\n",
    "    df_query_train['bm25_topk'] = df_query_train['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_train.to_pickle(train_pkl_path)\n",
    "else:\n",
    "    df_query_train = pd.read_pickle(train_pkl_path)\n",
    "\n",
    "if not os.path.exists(dev_pkl_path):\n",
    "    df_query_dev['bm25_topk'] = df_query_dev['tweet_text'].apply(lambda x: get_top_cord_uids(x))\n",
    "    df_query_dev.to_pickle(dev_pkl_path)\n",
    "else:\n",
    "    df_query_dev = pd.read_pickle(dev_pkl_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.) ColBERT reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) ColBERT finetuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions are meant to build BERT token embeddings from text. <br>\n",
    "Additionally, the document embeddings get pre-computed or loaded if they already exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get token embeddings of a specified text passage from some model\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    token_embeddings = token_embeddings[attention_mask] \n",
    "    return token_embeddings\n",
    "\n",
    "# pre compute all the token embeddings of the documents\n",
    "def build_and_save_doc_embeddings(\n",
    "    docs_df,\n",
    "    model_name,\n",
    "    save_dir,\n",
    "    max_len=512,\n",
    "    device=\"cuda\"\n",
    "):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name).to(device)\n",
    "    model.eval()\n",
    "\n",
    "    save_path = Path(\"doc_embeddings_\" + save_dir)\n",
    "    save_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    metadata_path = save_path / \"metadata.json\"\n",
    "    if metadata_path.exists():\n",
    "        with open(metadata_path, \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    else:\n",
    "        metadata = {}\n",
    "\n",
    "    print(\"Precomputing document embeddings.\")\n",
    "    for i, row in tqdm(docs_df.iterrows(), total=len(docs_df)):\n",
    "        doc_id = row.get(\"cord_uid\", f\"doc_{i}\")\n",
    "        file_path = save_path / f\"{doc_id}.pt\"\n",
    "\n",
    "        if file_path.exists() and doc_id in metadata:\n",
    "            continue\n",
    "\n",
    "        text = str(row.get('title', '')) + \" \" + str(row.get('abstract', '')) + \" Authors: \" + str(row.get('authors', ''))\n",
    "\n",
    "        inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=max_len)\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "        output = model(**inputs)\n",
    "        token_embeddings = output.last_hidden_state.squeeze(0)\n",
    "        attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "        token_embeddings = token_embeddings[attention_mask]\n",
    "\n",
    "        n_tokens = token_embeddings.size(0)\n",
    "        pad_len = max_len - n_tokens\n",
    "\n",
    "        if pad_len > 0:\n",
    "            padding = torch.zeros(pad_len, token_embeddings.size(1), device=device)\n",
    "            token_embeddings = torch.cat([token_embeddings, padding], dim=0)\n",
    "        else:\n",
    "            token_embeddings = token_embeddings[:max_len]\n",
    "\n",
    "        try:\n",
    "            torch.save(token_embeddings.cuda(), file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving document {doc_id}: {e}\")\n",
    "            continue\n",
    "\n",
    "        metadata[doc_id] = {\n",
    "            \"title\": row.get(\"title\", \"\"),\n",
    "            \"abstract\": row.get(\"abstract\", \"\"),\n",
    "            \"authors\": row.get(\"authors\", \"\"),\n",
    "            \"length\": min(n_tokens, max_len),\n",
    "            \"path\": str(file_path)\n",
    "        }\n",
    "\n",
    "    with open(metadata_path, \"w\") as f:\n",
    "        json.dump(metadata, f)\n",
    "\n",
    "    return metadata\n",
    "\n",
    "# either precompute or load precomputed doc embeddings\n",
    "def get_precomputed_doc_embeddings(save_name):\n",
    "    def split_at_slash(s):\n",
    "        if '/' in s:\n",
    "            return s.split('/', 1)\n",
    "        else:\n",
    "            return ['', s]\n",
    "        \n",
    "    if not os.path.exists(\"doc_embeddings_\" + split_at_slash(save_name)[1] + \"/metadata.json\"):\n",
    "        metadata = build_and_save_doc_embeddings(df_collection, model_name=save_name, save_dir=save_name, device=\"cuda\")\n",
    "    else:\n",
    "        with open(\"doc_embeddings_\" + save_name + \"/metadata.json\", \"r\") as f:\n",
    "            metadata = json.load(f)\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions create the triplet dataset (query, pos_doc, neg_doc) from the training dataset and define the SciBERT finetuning procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating training dataset by getting the positive and a random negative document for each query\n",
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, tokenizer, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.tokenizer = tokenizer\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# basic ColBERT scoring i.e. match matrix aggregation\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "    return max_sim_per_q.sum()\n",
    "\n",
    "# finetuning some BERT-model to get higher ColBERT-score \n",
    "# for the positive document than for the negative (per query)\n",
    "def bert_finetune(save_name, MARGIN=0.5, BATCH_SIZE=8, EPOCHS=6, LR=2e-5, num_negatives=1):    \n",
    "    model_name = \"allenai/scibert_scivocab_uncased\" # specify baseline BERT model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    metadata = get_precomputed_doc_embeddings(model_name)\n",
    "\n",
    "    # create training triplets\n",
    "    train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer, num_negatives)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # optimizer\n",
    "    DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.train()\n",
    "    model.to(DEVICE)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "    \n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = model(**inputs)\n",
    "            q_emb_batch = outputs.last_hidden_state  # [B, L, D]\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [emb[mask] for emb, mask in zip(q_emb_batch, attention_mask)]\n",
    "    \n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "    \n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = torch.load(metadata[pos_ids[i]][\"path\"]).to(DEVICE)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg_emb = torch.load(metadata[neg_ids[i]][\"path\"]).to(DEVICE)[:metadata[neg_ids[i]][\"length\"]]\n",
    "    \n",
    "                q_emb = q_embs[i]\n",
    "                score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "                score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "    \n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "    \n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "    \n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    model.save_pretrained(save_name)\n",
    "    tokenizer.save_pretrained(save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuning SciBERT with specified parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_finetune(\"colB_sciB_marg05\", MARGIN=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Finetuned ColBERT Reranking:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a dataframe containing queries and corresponding preranked document lists, embeds the queries through a forward pass in the finetuned SciBERT model, loads the precomputed document embeddings and computes a matchmatrix for each query-doc pair. Following the ColBERT approach, it then aggregates a single matching score from the matrix. Finally, it sorts the preranked document list according to the newly computed matching scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, model, save_name):\n",
    "    device = next(model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, model).to(device)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify model for re-ranking\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# pre-compute embeddings\n",
    "metadata = get_precomputed_doc_embeddings(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatchMatrixMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MatchMatrixMLP, self).__init__()\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sim_matrix):\n",
    "        \"\"\"\n",
    "        sim_matrix: [q_len, d_len]\n",
    "        Returns: scalar score\n",
    "        \"\"\"\n",
    "\n",
    "        # Query-wise pooling\n",
    "        max_per_q = sim_matrix.max(dim=1).values  # [q_len]\n",
    "        mean_per_q = sim_matrix.mean(dim=1)\n",
    "        std_per_q = sim_matrix.std(dim=1)\n",
    "\n",
    "        # Document-wise pooling\n",
    "        max_per_d = sim_matrix.max(dim=0).values\n",
    "        mean_per_d = sim_matrix.mean(dim=0)\n",
    "        std_per_d = sim_matrix.std(dim=0)\n",
    "\n",
    "        # Global pooling\n",
    "        global_max = sim_matrix.max()\n",
    "        global_mean = sim_matrix.mean()\n",
    "        global_std = sim_matrix.std()\n",
    "\n",
    "        # Aggregate features\n",
    "        features = torch.tensor([\n",
    "            max_per_q.mean(), mean_per_q.mean(), std_per_q.mean(),\n",
    "            max_per_d.mean(), mean_per_d.mean(), std_per_d.mean(),\n",
    "            global_max, global_mean, global_std,\n",
    "            max_per_q.max(), max_per_d.max(), global_std\n",
    "        ], device=sim_matrix.device)\n",
    "\n",
    "        return self.mlp(features.unsqueeze(0)).squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matchmlp(\n",
    "    bert_model,\n",
    "    tokenizer,\n",
    "    metadata,\n",
    "    train_dataset,\n",
    "    device=\"cuda\",\n",
    "    epochs=5,\n",
    "    margin=0.3,\n",
    "    batch_size=8,\n",
    "    lr=2e-5\n",
    "):\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    match_model = MatchMatrixMLP().to(device)\n",
    "    bert_model.to(device).eval()\n",
    "    match_model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(match_model.parameters(), lr=lr)\n",
    "    triplet_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def sim_matrix(q, d):\n",
    "        q_norm = q / q.norm(dim=1, keepdim=True)\n",
    "        d_norm = d / d.norm(dim=1, keepdim=True)\n",
    "        return torch.matmul(q_norm, d_norm.T)  # [q_len, d_len]\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(triplet_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "\n",
    "            # Encode queries\n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            with torch.no_grad():\n",
    "                q_output = bert_model(**inputs)\n",
    "\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [emb[mask] for emb, mask in zip(q_output.last_hidden_state, attention_mask)]\n",
    "\n",
    "            loss = 0.0\n",
    "            for i in range(len(queries)):\n",
    "                q_emb = q_embs[i]\n",
    "                d_pos = torch.load(metadata[pos_ids[i]][\"path\"]).to(device)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg = torch.load(metadata[neg_ids[i]][\"path\"]).to(device)[:metadata[neg_ids[i]][\"length\"]]\n",
    "\n",
    "                sim_pos = sim_matrix(q_emb, d_pos)\n",
    "                sim_neg = sim_matrix(q_emb, d_neg)\n",
    "\n",
    "                score_pos = match_model(sim_pos)\n",
    "                score_neg = match_model(sim_neg)\n",
    "\n",
    "                loss += F.relu(margin + score_neg - score_pos)\n",
    "\n",
    "            loss = loss / len(queries)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
    "\n",
    "    return match_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a6e2892eb744ed5a8d5533f0c766ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 718.9339\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f211edc8ec41359c978c7e968c6837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 602.8695\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a6adc1fdcf49da9bba6e0b322728d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 461.1193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b5bf65dcb964479af80c6a85b0118d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 341.4806\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8b7567b4ffa49dfa208bbf19d85aab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 262.1859\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c69fceaa7a46eba0baf07632ccd8f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 212.2987\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4269cdf09b54b70a1262c1e17e19704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 7:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Loss = 180.7391\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c789ec2a624fccb60a20d1469fbc7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 8:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Loss = 160.4647\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "700af6e07236430bb188cedaf788b28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 9:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Loss = 147.2528\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c25bc3e4b74004ab188d476681208c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 10:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 138.4881\n"
     ]
    }
   ],
   "source": [
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "scibert_model = AutoModel.from_pretrained(model_name)\n",
    "train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer)\n",
    "\n",
    "mlp_model = train_matchmlp(\n",
    "    bert_model=scibert_model,\n",
    "    tokenizer=tokenizer,\n",
    "    metadata=metadata,\n",
    "    train_dataset=train_dataset,\n",
    "    device=\"cuda\",\n",
    "    epochs=10,\n",
    "    margin=0.5,\n",
    "    batch_size=8,\n",
    "    lr=2e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_mlp(df, metadata, tokenizer, bert_model, match_model, save_name):\n",
    "    device = next(bert_model.parameters()).device\n",
    "    bert_model.eval()\n",
    "    match_model.eval()\n",
    "\n",
    "    doc_embeddings = {\n",
    "        doc_id: torch.load(meta[\"path\"], map_location=device)[:meta[\"length\"]]\n",
    "        for doc_id, meta in metadata.items()\n",
    "    }\n",
    "\n",
    "    df[save_name + \"_scores\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            doc_ids = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, bert_model, device=device)\n",
    "            q_emb = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc_id in doc_ids:\n",
    "                d_emb = doc_embeddings[doc_id]\n",
    "                d_emb = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim = torch.matmul(q_emb, d_emb.T)  # [q_len, d_len]\n",
    "                score = match_model(sim).item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + \"_scores\"] = scores\n",
    "\n",
    "    df[save_name + \"_topk\"] = df.apply(\n",
    "        lambda row: [doc for doc, _ in sorted(\n",
    "            zip(row['bm25_topk'], row[save_name + '_scores']),\n",
    "            key=lambda x: x[1], reverse=True\n",
    "        )],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eee5129b95714ef6906c65dc7d76492e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reranked = rerank_with_cnn(\n",
    "    df=df_query_dev,\n",
    "    metadata=metadata,\n",
    "    tokenizer=tokenizer,\n",
    "    bert_model=scibert_model,\n",
    "    match_model=mlp_model,\n",
    "    save_name=\"sciB_mlp_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class MatchPyramid(nn.Module):\n",
    "    def __init__(self, input_channels=1, conv_channels=16, pool_size=(6, 6)):\n",
    "        super(MatchPyramid, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 8, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, conv_channels, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.pool = nn.AdaptiveMaxPool2d(pool_size)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_channels * pool_size[0] * pool_size[1], 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, sim_matrix):\n",
    "        # sim_matrix: [q_len, d_len]\n",
    "        x = sim_matrix.unsqueeze(0).unsqueeze(0)  # [1, 1, q_len, d_len]\n",
    "        x = self.conv(x)                          # [1, C, H, W]\n",
    "        x = self.pool(x)                          # [1, C, pool_H, pool_W]\n",
    "        score = self.mlp(x)                       # [1, 1]\n",
    "        return score.squeeze()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_matchpyramid(\n",
    "    bert_model,\n",
    "    tokenizer,\n",
    "    metadata,\n",
    "    train_dataset,\n",
    "    device=\"cuda\",\n",
    "    epochs=6,\n",
    "    margin=0.5,\n",
    "    batch_size=8,\n",
    "    lr=2e-5\n",
    "):\n",
    "    from torch.utils.data import DataLoader\n",
    "\n",
    "    model = MatchPyramid().to(device)\n",
    "    bert_model.to(device).eval()\n",
    "    model.train()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def get_sim(q, d):\n",
    "        q_norm = q / q.norm(dim=1, keepdim=True)\n",
    "        d_norm = d / d.norm(dim=1, keepdim=True)\n",
    "        return torch.matmul(q_norm, d_norm.T)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0.0\n",
    "        for queries, pos_ids, neg_ids in tqdm(dataloader, desc=f\"Epoch {epoch+1}\"):\n",
    "            inputs = tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = bert_model(**inputs)\n",
    "                attention_mask = inputs[\"attention_mask\"].bool()\n",
    "                q_embs = [o[mask] for o, mask in zip(output.last_hidden_state, attention_mask)]\n",
    "\n",
    "            loss = 0.0\n",
    "            for i in range(len(queries)):\n",
    "                q_emb = q_embs[i]\n",
    "                d_pos = torch.load(metadata[pos_ids[i]][\"path\"]).to(device)[:metadata[pos_ids[i]][\"length\"]]\n",
    "                d_neg = torch.load(metadata[neg_ids[i]][\"path\"]).to(device)[:metadata[neg_ids[i]][\"length\"]]\n",
    "\n",
    "                sim_pos = get_sim(q_emb, d_pos)\n",
    "                sim_neg = get_sim(q_emb, d_neg)\n",
    "\n",
    "                score_pos = model(sim_pos)\n",
    "                score_neg = model(sim_neg)\n",
    "\n",
    "                loss += F.relu(margin + score_neg - score_pos)\n",
    "\n",
    "            loss = loss / len(queries)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}: Loss = {total_loss:.4f}\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f7840a279744249b8f7b70b9f78c1f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 341.4415\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad8e33e3e70c44be94dc4317054a5dfe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Loss = 161.8874\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d08715b988884b4a82eba23c4916c2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Loss = 150.7042\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2116545a0a734b09a6edddf6e89f5fca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Loss = 144.8148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c33d73519ef74b53a6dbdcd7831cb365",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Loss = 141.0205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9551c9d19894e9e8fcab9e30ca61dd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Loss = 138.0958\n"
     ]
    }
   ],
   "source": [
    "model_name = \"colB_sciB_marg05\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "scibert_model = AutoModel.from_pretrained(model_name)\n",
    "train_dataset = ColBERTTripletDataset(df_query_train, metadata, tokenizer)\n",
    "\n",
    "matchpyramid_model = train_matchpyramid(\n",
    "    bert_model=scibert_model,\n",
    "    tokenizer=tokenizer,\n",
    "    metadata=metadata,\n",
    "    train_dataset=train_dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cnn_model.state_dict(), \"matchcnn_model_1.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank_with_matchpyramid(df, metadata, tokenizer, bert_model, match_model, save_name):\n",
    "    device = next(bert_model.parameters()).device\n",
    "    bert_model.eval()\n",
    "    match_model.eval()\n",
    "\n",
    "    doc_embeddings = {\n",
    "        doc_id: torch.load(meta[\"path\"], map_location=device)[:meta[\"length\"]]\n",
    "        for doc_id, meta in metadata.items()\n",
    "    }\n",
    "\n",
    "    df[save_name + \"_scores\"] = [[] for _ in range(len(df))]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            doc_ids = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, bert_model, device=device)\n",
    "            q_emb = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc_id in doc_ids:\n",
    "                d_emb = doc_embeddings[doc_id]\n",
    "                d_emb = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim = torch.matmul(q_emb, d_emb.T)\n",
    "                score = match_model(sim).item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + \"_scores\"] = scores\n",
    "\n",
    "    df[save_name + \"_topk\"] = df.apply(\n",
    "        lambda row: [doc for doc, _ in sorted(zip(row['bm25_topk'], row[save_name + '_scores']), key=lambda x: x[1], reverse=True)],\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = MatchCNN(input_size=32)\n",
    "cnn_model.load_state_dict(torch.load(\"matchcnn_model_1.pt\"))\n",
    "cnn_model.to(\"cuda\")\n",
    "cnn_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b293612dd7444f9dbe02d682ef948b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_reranked = rerank_with_matchpyramid(\n",
    "    df=df_query_dev,\n",
    "    metadata=metadata,\n",
    "    tokenizer=tokenizer,\n",
    "    bert_model=scibert_model,\n",
    "    match_model=matchpyramid_model,\n",
    "    save_name=\"sciB_matchpyramid_1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QVKBlTCZUMSc"
   },
   "source": [
    "# 3) Evaluation\n",
    "The following code evaluates the BM25 retrieval baseline on the query set using the Mean Reciprocal Rank score (MRR@5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1742976555898,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "c-vdGWXXTgjZ"
   },
   "outputs": [],
   "source": [
    "# Evaluate retrieved candidates using MRR@k\n",
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- Finetuned ColBERT (SciBERT) Reranking ----\n",
      "MRR@5 on dev set: 0.6806309523809524\n"
     ]
    }
   ],
   "source": [
    "# ---- ColBERT Re-Ranking ----\n",
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "results_dev = get_performance_mrr(df_query_dev, 'cord_uid', f'{model_name}_topk')\n",
    "print(\"---- Finetuned ColBERT (SciBERT) Reranking ----\")\n",
    "print(f\"MRR@5 on dev set: {results_dev[5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RazcRTV84KQC"
   },
   "source": [
    "# 4) Exporting results to prepare the submission on Codalab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 39,
     "status": "ok",
     "timestamp": 1742976603546,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "DFng4ocDw3Hk"
   },
   "outputs": [],
   "source": [
    "model_name = \"colB_sciB_marg05\"\n",
    "\n",
    "df_query_test['preds'] = df_query_test[f'{model_name}_topk'].apply(lambda x: x[:5])\n",
    "df_query_test[\"post_id\"] = df_query_test[\"post_id\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1742976608184,
     "user": {
      "displayName": "Yavuz",
      "userId": "01318046262282431930"
     },
     "user_tz": -60
    },
    "id": "nAVBQYh_xP8O"
   },
   "outputs": [],
   "source": [
    "df_query_test[['post_id', 'preds']].to_csv('predictions.tsv', index=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying out different combinations of margin and number of negative document samples for training. <br>\n",
    "Result: **margin of 0.5** seems to work best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_performance_mrr(data, col_gold, col_pred, list_k = [1, 5, 10]):\n",
    "    d_performance = {}\n",
    "    for k in list_k:\n",
    "        data[\"in_topx\"] = data.apply(lambda x: (1/([i for i in x[col_pred][:k]].index(x[col_gold]) + 1) if x[col_gold] in [i for i in x[col_pred][:k]] else 0), axis=1)\n",
    "        #performances.append(data[\"in_topx\"].mean())\n",
    "        d_performance[k] = data[\"in_topx\"].mean()\n",
    "    return d_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç Combination 1/9 ‚Üí colB_sciB_m3_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e09fd20c50d409ebe8b5d34d2509a27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 121.9535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ce646d659fb4e41b08da114668cbaf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 40.3961\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7006d7f1386a415097e935b7caabf68b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 23.0165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd8b1e60ce547c28be5201422780adc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 12.7019\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9d31848ba8425192565230a9a06a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 7.5942\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e6b108b62d7450c95fea059f8215ea7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 8.0212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "434f634c3cd24aec8b6bcbd9cc159524",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa40856f46154657ac80b44ffc783e66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6537142857142857\n",
      "\n",
      "üîç Combination 2/9 ‚Üí colB_sciB_m3_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b25f30c0936409fb0fbb0dcdd7401fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 198.2437\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91809150dd6e432489c4d4ae3f51766f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 72.1588\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "427c256ec2d64d46b75eaa459975ba7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 46.9973\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40265b6e4e114bb28f3e837fbad949dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 28.1074\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a98ebe27ef4c4702a8c3c9d0be795069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 23.5954\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccacc3304416419aae3e09b1ca095ab5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 16.7373\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a73804eaf94e679dab3916598549d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b5ad6ecad14b73b81c3696a13a008e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6477142857142858\n",
      "\n",
      "üîç Combination 3/9 ‚Üí colB_sciB_m3_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6604e85353f4c1a96259cadd04081e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 352.6436\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d37bf50ff4c047499d2dfb370889d950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 134.0740\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e271355e337447288da685f9b87b7973",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 63.8498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78562c0afd264b4584e06c645241410c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 42.9125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09550471fdbe4919b96ff06abdd36478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 31.2010\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9277c4e6eb546dd863ff12062d79515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 29.3307\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4115a60c084d6395f46b080e7fd6c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2360f807306d40b89a8fc0ba1090fb97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6118333333333333\n",
      "\n",
      "üîç Combination 4/9 ‚Üí colB_sciB_m4_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593927cd5bca4ca3ac111a150d9b53a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 137.3641\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57159f0497db4ae4ad6d36681103cac4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 52.0689\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2e20806081b4f37b21276934af8b242",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 23.6070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944a5737a791440a914e9b5d11d54e1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 17.4979\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b31d92c4e34faf9b43a4dd3611b5c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 9.9772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbeafdd544164f73858f00e68a63d0d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 12.9181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f98e12e3bcf8477fae34ef1e10415b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb2ada83d4e45faadb6c6d5624716c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6574285714285714\n",
      "\n",
      "üîç Combination 5/9 ‚Üí colB_sciB_m4_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ddde22bf034ba98eaeccb4fe279cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 227.4885\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0e6a8f8fbbd43598593fa5926d2b888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 92.5719\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "617c1746f60642bd971136494b77f48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 51.2666\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ef09260d944427b93542f1894133e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 30.8887\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac6e855bac04f9ebb710b8d465f8f2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 23.0024\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2b193e5ef064a5eafa9104ed9f9905a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 21.4273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce41852813a4b42963c1e89c6ec7768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b47536aeb7564a889d467e9bee1ef001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6502738095238095\n",
      "\n",
      "üîç Combination 6/9 ‚Üí colB_sciB_m4_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bc0f00d8674524a4c54db1c280d060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 359.6384\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c4f4165e174428abdd3251ec323e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 131.8794\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bce1c803e545c5a5a1c4bfce51dc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 63.0106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4db41e5652b449cd8feb4ed1cf6b9ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 50.9670\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "653aca41aac94923a2b5abff30e99165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 38.3159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc814c63b0741179b9ffafc0160d6d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 27.8490\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b82887947f449b88699c1135c500131",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e8595fee134e92a18585517abb9b19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6360357142857143\n",
      "\n",
      "üîç Combination 7/9 ‚Üí colB_sciB_m5_neg1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2e8abe7a3b475d824558eb9512204b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 160.1443\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7de1ecf5214502a22416d6282d2b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 65.4520\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e46e209ea454d08b9cc42b2ecf33f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 29.0368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31aa0fc891e9434a94f198165c36d72f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 29.2456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554e2d964e5d458aa9b0c251ca8cef50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 15.5198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8da3178ba6a8410b9e637e6fa5752e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/1607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 9.6190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8d828954cc4db39e478692e6ccd77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9106981208d4bbd9057d9294488308c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6610238095238096\n",
      "\n",
      "üîç Combination 8/9 ‚Üí colB_sciB_m5_neg2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d66b958180604afbbae332786422c136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 257.0342\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58015fc0f4274bb59808c8af376bf9cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 89.1174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba91ac191984cd4bfb8bc659b1c3556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 41.8070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fc8466afb24a0c9c22d200ea70d180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 29.2456\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c2a5703f7ef4c45acc8809d3904d341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 21.2743\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1c5421d9bd42fcafc5d75ec2080b08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/3214 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 18.1380\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbbfaaf3b73b43de902d88bcf4c6b107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d493c1b3b046b8b3878cbd77466f29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.639345238095238\n",
      "\n",
      "üîç Combination 9/9 ‚Üí colB_sciB_m5_neg4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d81e1017b6c64e53901d6bc61540cd3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 Loss: 395.6334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbc07155334146f387fa3a27d7e95942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 2:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 Loss: 110.6216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c71da866c4fadbec85a2ede4b2b46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 3:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 Loss: 54.9982\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8eca26adc2b49649f7c278260ccf9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 4:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 Loss: 41.8254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0df868072a7840d8b75f19ff664b015d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 5:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 Loss: 32.5702\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ef41191df1453dbb31ecbedb0c7a33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 6:   0%|          | 0/6427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 Loss: 31.5070\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a44c1bb14884babb2160e056665fbc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7718 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2638ace67ba542a3b901180dcb591135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1400 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR@5: 0.6259285714285714\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import random, torch, numpy as np\n",
    "\n",
    "param_grid = {\n",
    "    \"margin\":        [0.3, 0.4, 0.5],\n",
    "    \"num_negatives\": [1, 2, 4]\n",
    "}\n",
    "keys, values = zip(*param_grid.items())\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "for i, (margin, num_neg) in enumerate(product(*values), 1):\n",
    "    set_seed()\n",
    "    model_name = f\"colB_sciB_m{str(margin)[-1]}_neg{num_neg}\"\n",
    "    print(f\"\\nüîç Combination {i}/9 ‚Üí {model_name}\")\n",
    "\n",
    "    scibert_finetune(\n",
    "        save_name      = model_name,\n",
    "        MARGIN         = margin,\n",
    "        BATCH_SIZE     = 8,\n",
    "        EPOCHS         = 6,\n",
    "        LR             = 2e-5,\n",
    "        num_negatives  = num_neg\n",
    "    )\n",
    "\n",
    "    # ---------- Evaluation ----------\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model     = AutoModel.from_pretrained(model_name)\n",
    "    metadata  = pre_compute_embeddings(model_name)\n",
    "\n",
    "    df_query_dev = rerank(df_query_dev, metadata, tokenizer, model, model_name)\n",
    "    mrr_scores   = get_performance_mrr(df_query_dev, \"cord_uid\", f\"{model_name}_topk\")\n",
    "    print(\"MRR@5:\", mrr_scores[5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "import torch.nn as nn\n",
    "\n",
    "# hyperparameter\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 4\n",
    "LR = 2e-5\n",
    "MARGIN = 0.2\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# load model\n",
    "query_model_name = \"digitalepidemiologylab/covid-twitter-bert\"\n",
    "doc_model_name = \"allenai/scibert_scivocab_uncased\"\n",
    "\n",
    "query_tokenizer = AutoTokenizer.from_pretrained(query_model_name)\n",
    "doc_tokenizer = AutoTokenizer.from_pretrained(doc_model_name)\n",
    "\n",
    "query_model = AutoModel.from_pretrained(query_model_name).to(DEVICE)\n",
    "doc_model = AutoModel.from_pretrained(doc_model_name).to(DEVICE)\n",
    "\n",
    "# projection to same dimensions\n",
    "query_projection = nn.Linear(1024, 768).to(DEVICE)\n",
    "\n",
    "# dataset creation\n",
    "class ColBERTTripletDataset(Dataset):\n",
    "    def __init__(self, df, metadata, num_negatives=1):\n",
    "        self.data = []\n",
    "        self.metadata = metadata\n",
    "        for _, row in df.iterrows():\n",
    "            query = row[\"tweet_text\"]\n",
    "            pos = row[\"cord_uid\"]\n",
    "            negatives = [doc for doc in row[\"bm25_topk\"] if doc != pos]\n",
    "            if negatives:\n",
    "                for _ in range(num_negatives):\n",
    "                    neg = random.choice(negatives)\n",
    "                    self.data.append((query, pos, neg))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# helper functions\n",
    "def get_token_embeddings(text, tokenizer, model, device='cpu'):\n",
    "    inputs = tokenizer(text, return_tensors='pt', truncation=True, max_length=512)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    outputs = model(**inputs)\n",
    "    token_embeddings = outputs.last_hidden_state.squeeze(0)\n",
    "    attention_mask = inputs['attention_mask'].squeeze(0).bool()\n",
    "    return token_embeddings[attention_mask]\n",
    "\n",
    "def get_doc_embedding(doc_id, metadata, tokenizer, model, device):\n",
    "    text = f\"{metadata[doc_id]['title']} {metadata[doc_id]['abstract']} Authors: {metadata[doc_id]['authors']}\"\n",
    "    return get_token_embeddings(text, tokenizer, model, device)\n",
    "\n",
    "def colbert_score_from_emb(q_emb, d_emb):\n",
    "    q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "    d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "    sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "    return sim_matrix.max(dim=1).values.sum()\n",
    "\n",
    "# training function\n",
    "def train_colbert_dual_encoder(df_query_train, metadata):\n",
    "    dataset = ColBERTTripletDataset(df_query_train, metadata)\n",
    "    loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "    query_model.train()\n",
    "    doc_model.train()\n",
    "    query_projection.train()\n",
    "\n",
    "    optimizer = torch.optim.AdamW(\n",
    "        list(query_model.parameters()) +\n",
    "        list(doc_model.parameters()) +\n",
    "        list(query_projection.parameters()),\n",
    "        lr=LR\n",
    "    )\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0.0\n",
    "        for batch in tqdm(loader, desc=f\"Epoch {epoch+1}\"):\n",
    "            queries, pos_ids, neg_ids = batch\n",
    "\n",
    "            inputs = query_tokenizer(list(queries), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "            inputs = {k: v.to(DEVICE) for k, v in inputs.items()}\n",
    "            outputs = query_model(**inputs)\n",
    "            q_emb_batch = outputs.last_hidden_state\n",
    "            attention_mask = inputs[\"attention_mask\"].bool()\n",
    "            q_embs = [query_projection(emb[mask]) for emb, mask in zip(q_emb_batch, attention_mask)]\n",
    "\n",
    "            score_pos_list = []\n",
    "            score_neg_list = []\n",
    "\n",
    "            for i in range(len(queries)):\n",
    "                d_pos_emb = get_doc_embedding(pos_ids[i], metadata, doc_tokenizer, doc_model, DEVICE)\n",
    "                d_neg_emb = get_doc_embedding(neg_ids[i], metadata, doc_tokenizer, doc_model, DEVICE)\n",
    "                q_emb = q_embs[i]\n",
    "\n",
    "                score_pos = colbert_score_from_emb(q_emb, d_pos_emb)\n",
    "                score_neg = colbert_score_from_emb(q_emb, d_neg_emb)\n",
    "\n",
    "                score_pos_list.append(score_pos)\n",
    "                score_neg_list.append(score_neg)\n",
    "\n",
    "            score_pos_batch = torch.stack(score_pos_list)\n",
    "            score_neg_batch = torch.stack(score_neg_list)\n",
    "\n",
    "            loss = F.relu(MARGIN + score_neg_batch - score_pos_batch).mean()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1} Loss: {total_loss:.4f}\")\n",
    "\n",
    "    query_model.save_pretrained(\"finetuned_ctbert\")\n",
    "    query_tokenizer.save_pretrained(\"finetuned_ctbert\")\n",
    "    doc_model.save_pretrained(\"finetuned_scibert\")\n",
    "    doc_tokenizer.save_pretrained(\"finetuned_scibert\")\n",
    "    torch.save(query_projection.state_dict(), \"query_projection.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_colbert_dual_encoder(df_query_train, metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rerank(df, metadata, tokenizer, q_model, d_model, save_name):\n",
    "    device_q = next(q_model.parameters()).device\n",
    "    device_d = next(d_model.parameters()).device\n",
    "    df[save_name + '_scores'] = [[] for _ in range(len(df))]\n",
    "\n",
    "    query_projection = nn.Linear(1024, 768)\n",
    "    query_projection.load_state_dict(torch.load(\"query_projection.pt\"))\n",
    "    query_projection.to(device_q)\n",
    "    query_projection.eval()\n",
    "\n",
    "    doc_embeddings = {}\n",
    "    for doc_id, data in metadata.items():\n",
    "        emb = torch.load(data[\"path\"], map_location=\"cpu\")\n",
    "        doc_embeddings[doc_id] = emb\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, row in tqdm(df.iterrows(), total=len(df)):\n",
    "            tweet_text = row['tweet_text']\n",
    "            pre_ranked_docs = row['bm25_topk']\n",
    "\n",
    "            q_emb = get_token_embeddings(tweet_text, tokenizer, q_model, device=device_q)\n",
    "            q_emb = query_projection(q_emb)\n",
    "            q_norm = q_emb / q_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "            scores = []\n",
    "            for doc in pre_ranked_docs:\n",
    "                emb = doc_embeddings[doc].to(device_d)\n",
    "                length = metadata[doc][\"length\"]\n",
    "                d_emb = emb[:length]\n",
    "                d_norm = d_emb / d_emb.norm(dim=1, keepdim=True)\n",
    "\n",
    "                sim_matrix = torch.matmul(q_norm, d_norm.T)\n",
    "                max_sim_per_q = sim_matrix.max(dim=1).values\n",
    "                score = max_sim_per_q.sum().item()\n",
    "                scores.append(score)\n",
    "\n",
    "            df.at[idx, save_name + '_scores'] = scores\n",
    "\n",
    "    def sort_docs_by_score(row):\n",
    "        doc_ids = row['bm25_topk']\n",
    "        scores = row[save_name + '_scores']\n",
    "        sorted_docs = [doc for doc, _ in sorted(zip(doc_ids, scores), key=lambda x: x[1], reverse=True)]\n",
    "        return sorted_docs\n",
    "\n",
    "    df[save_name + '_topk'] = df.apply(sort_docs_by_score, axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7718/7718 [03:40<00:00, 34.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# pre-compute embeddings\n",
    "metadata = pre_compute_embeddings(\"finetuned_scibert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1400/1400 [02:21<00:00,  9.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# re-rank BM25 list for dev data\n",
    "df_query_dev = rerank(df_query_dev, metadata, tokenizer, query_model, doc_model, \"sciCtBERT-1\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
